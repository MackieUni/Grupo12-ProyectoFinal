{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# # INTRODUCCI√ìN"
      ],
      "metadata": {
        "id": "X12YqU6Z0X9m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizaci√≥n de Arquitecturas de Deep Learning para Detecci√≥n y Conteo Autom√°tico de Fauna en Surveys A√©reos de Alta Resoluci√≥n\n",
        "\n",
        "## Proyecto Guacamaya: Sistema Automatico de Detecci√≥n de Fauna Africana"
      ],
      "metadata": {
        "id": "XtExK-jAysx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instituciones:** Microsoft AI for Good Lab, Centro SINFON√çA - Universidad de los Andes, Instituto Sinchi, Instituto Alexander von Humboldt\n",
        "\n",
        "**Grupo 12:** Jorge Mario Guaquet√°, Daniel Santiago Trujillo, Inmaculada Concepci√≥n Rond√≥n, Daniela Alexandra Ortiz Santacruz\n",
        "\n",
        "**Dataset:** DelPlan 2022 - ~2,000 im√°genes a√©reas de 5000x4000 p√≠xeles (20MP)\n",
        "**Especies:** Buffalo, Elephant, Kudu, Topi, Warthog, Waterbuck"
      ],
      "metadata": {
        "id": "aedm_XfY0-fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. DESCRIPCI√ìN DEL PROYECTO"
      ],
      "metadata": {
        "id": "sMnlfVgN1QjS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Contexto\n",
        "\n",
        "Los *Aerial Wildlife Surveys* son fundamentales para el monitoreo poblacional de fauna en ecosistemas extensos. El m√©todo tradicional (conteo manual) presenta limitaciones cr√≠ticas: fatiga visual, errores por turbulencia, tiempo limitado de observaci√≥n, variabilidad inter-observador y costos elevados."
      ],
      "metadata": {
        "id": "AReGPRzh1yoZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Problema Principal\n",
        "\n",
        "Las im√°genes a√©reas de ultra-alta resoluci√≥n (5000√ó4000 p√≠xeles) exceden las capacidades de memoria de GPUs est√°ndar. La arquitectura HerNet actual presenta:\n",
        "\n",
        "- **Restricciones de memoria:** imposibilidad de procesar im√°genes completas\n",
        "- **Detecciones duplicadas:** animales grandes generan m√∫ltiples puntos cercanos  \n",
        "- **Post-procesamiento ineficiente:** falta de consolidaci√≥n de detecciones"
      ],
      "metadata": {
        "id": "LYy57JDX2D2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Arquitectura H√≠brida Multi-Scale (AHMS)** con tres componentes:\n",
        "\n",
        "- **Patch Management Inteligente (PMI):** Segmentaci√≥n adaptativa con *overlapping*\n",
        "- **Multi-Scale Feature Fusion (MSFF):** Procesamiento en m√∫ltiples resoluciones  \n",
        "- **Post-Processing Optimization (PPO):** Clustering espacial y NMS adaptativo\n"
      ],
      "metadata": {
        "id": "RQkw9Nje2fEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Impacto Esperado\n",
        "\n",
        "- **Automatizaci√≥n completa** de *surveys* eliminando errores humanos\n",
        "- **Reducci√≥n de costos** operativos\n",
        "- **Escalabilidad** para monitoreo continuo  \n",
        "- **Contribuci√≥n a repositorio open-source** (+65,000 descargas)"
      ],
      "metadata": {
        "id": "r7qPicJj2sIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. OBJETIVOS DEL PROYECTO"
      ],
      "metadata": {
        "id": "UIoTDnpj3Qeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Objetivo General\n",
        "\n",
        "Desarrollar y validar una arquitectura optimizada de *deep learning* para detecci√≥n y conteo autom√°tico de fauna en im√°genes a√©reas de ultra-alta resoluci√≥n, superando las limitaciones actuales de HerNet."
      ],
      "metadata": {
        "id": "sgFjZsF74Fkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Objetivos Espec√≠ficos\n",
        "\n",
        "1. Optimizar manejo de memoria con estrategias eficientes de *patchado*\n",
        "2. Implementar algoritmos avanzados de post-procesamiento\n",
        "3. Comparar arquitecturas (HerNet vs YOLO vs h√≠bridas)\n",
        "4. Desarrollar t√©cnicas de muestreo inteligente para balance de datos\n",
        "5. Validar robustez bajo condiciones variables\n",
        "6. Establecer m√©tricas especializadas para *wildlife counting*"
      ],
      "metadata": {
        "id": "T3L-6G1p4oi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Metas de Mejora (vs HerNet Original)\n",
        "\n",
        "| M√©trica | Estado Actual | Meta | Mejora |\n",
        "|---------|---------------|------|---------|\n",
        "| **AP@0.5** | 0.67 | >0.75 | +12% |\n",
        "| **MAE** | 4.2 | <3.0 | -30% error |\n",
        "| **MAPE** | 18.3% | <12% | -35% error |\n",
        "| **Tiempo de Procesamiento** | ~45s | <20s | Optimizaci√≥n |"
      ],
      "metadata": {
        "id": "nsDGbGev42a1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3. PREGUNTAS DE INVESTIGACI√ìN"
      ],
      "metadata": {
        "id": "u7gJUkJZ6FjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Preguntas T√©cnicas\n",
        "\n",
        "1. **Estrategia de patchado:** ¬øCu√°l es la estrategia √≥ptima de *patchado* (tama√±o, *overlapping*) para im√°genes de 20MP que maximice detecciones y minimice uso de memoria?\n",
        "\n",
        "2. **Arquitectura √≥ptima:** ¬øQu√© arquitectura (HerNet, YOLOv8, YOLOv11, DETR, o h√≠brida) ofrece el mejor balance entre precisi√≥n, *recall* y velocidad para *point detection*?\n",
        "\n",
        "3. **Detecciones duplicadas:** ¬øC√≥mo eliminar eficientemente detecciones duplicadas sin perder animales reales en √°reas de alta densidad?\n",
        "\n",
        "4. **Data augmentation:** ¬øQu√© t√©cnicas de *data augmentation* son m√°s efectivas para simular condiciones reales de iluminaci√≥n, clima y terreno?\n",
        "\n",
        "5. **Balance de datos:** ¬øCu√°l es el *ratio* √≥ptimo de *patches* positivos/negativos durante entrenamiento para evitar sesgo hacia *backgrounds*?"
      ],
      "metadata": {
        "id": "d1_GoaJS6dQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Preguntas de Aplicaci√≥n\n",
        "\n",
        "1. **Generalizaci√≥n a nuevas especies:** ¬øC√≥mo generaliza el modelo a nuevas especies no vistas en entrenamiento?\n",
        "\n",
        "2. **M√©tricas para conservacionistas:** ¬øQu√© m√©tricas reflejan mejor las necesidades reales de conservacionistas (error de conteo vs precisi√≥n de localizaci√≥n)?\n",
        "\n",
        "3. **Robustez ambiental:** ¬øC√≥mo afectan variaciones estacionales y de *habitat* la performance del modelo?\n",
        "\n",
        "4. **Estimaci√≥n de densidad:** ¬øEs posible estimar densidad poblacional adem√°s del conteo individual?\n",
        "\n",
        "5. **Transferibilidad:** ¬øC√≥mo transferir el modelo a otros ecosistemas (Amazon√≠a, Serengeti, etc.)?"
      ],
      "metadata": {
        "id": "65j1j0jv6sUh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. METODOLOG√çA\n",
        "\n",
        "## 4.1 Entendimiento y Preparaci√≥n de los Datos\n",
        "### Configuraci√≥n del Entorno\n",
        "El procesamiento se realiz√≥ en **Google Colab Pro** para aprovechar mayor potencia de GPU, montando Google Drive para acceder al dataset de ~2,000 im√°genes de 20MP."
      ],
      "metadata": {
        "id": "I__ka-V17feI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estructura  &  Distribuci√≥n del Dataset\n",
        "- **Train:** 928 im√°genes\n",
        "- **Validation:** 111 im√°genes  \n",
        "- **Test:** 258 im√°genes"
      ],
      "metadata": {
        "id": "qfv707Jt71Ix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Herramientas y Frameworks\n",
        "Para el desarrollo se utiliz√≥ Ultralytics YOLO para la implementaci√≥n de modelos de detecci√≥n de objetos."
      ],
      "metadata": {
        "id": "-jSGRlCI-R14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "jQGIdwYd-9Sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Entrenamiento del Modelo Base\n",
        "\n",
        "Se implement√≥ YOLO11s como arquitectura base para la detecci√≥n de fauna, configurando un entrenamiento inicial de 20 √©pocas para validaci√≥n r√°pida del pipeline.\n",
        "\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Configuraci√≥n inicial del modelo YOLO11s\n",
        "model = YOLO(\"yolo11s.pt\")\n",
        "\n",
        "# Par√°metros de entrenamiento r√°pido para validaci√≥n\n",
        "results = model.train(\n",
        "    data=DATA_YAML,\n",
        "    epochs=20,\n",
        "    imgsz=1024,\n",
        "    batch=8,\n",
        "    project=RESULTS_DIR,\n",
        "    name=\"retrain_yolo11s\"\n",
        ")"
      ],
      "metadata": {
        "id": "mu8J6hej_AoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Resultados del Entrenamiento Inicial\n",
        "\n",
        "El entrenamiento de 20 √©pocas complet√≥ en **1.12 horas**, obteniendo los siguientes resultados de validaci√≥n:\n",
        "\n",
        "**M√©tricas Principales:**\n",
        "- **mAP@50:** 0.332\n",
        "- **Precisi√≥n (Box P):** 0.317  \n",
        "- **Recall (R):** 0.365\n",
        "- **mAP@50-95:** 0.11\n",
        "\n",
        "**Rendimiento por Especie:**\n",
        "- **Kudu (K):** mAP@50 = 0.556 (mejor rendimiento)\n",
        "- **Buffalo (B):** mAP@50 = 0.495\n",
        "- **Elephant (E):** mAP@50 = 0.400\n",
        "- **Warthog (WH):** mAP@50 = 0.0515 (mayor desaf√≠o)\n",
        "\n",
        "**Inferencia:** 10.0ms por imagen (Tesla T4)"
      ],
      "metadata": {
        "id": "7M_lU9vT4ApY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4.4 - Configuraci√≥n y Carga de Datos"
      ],
      "metadata": {
        "id": "558aj1CgImwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AN√ÅLISIS DE RESULTADOS DEL ENTRENAMIENTO YOLO\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Configuraci√≥n para gr√°ficos profesionales\n",
        "plt.style.use('default')\n",
        "\n",
        "# Cargar resultados del entrenamiento\n",
        "csv_path = \"/content/drive/MyDrive/MAIA_Final_Project_2025/results_yolo11/retrain_yolo11s/results.csv\"\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "print(f\"Total de epochs entrenadas: {len(df)}\")\n",
        "print(f\"M√©tricas disponibles: {list(df.columns)}\")"
      ],
      "metadata": {
        "id": "gBubsRo8IjYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4.4.5 - An√°lisis de P√©rdidas (Loss)"
      ],
      "metadata": {
        "id": "WQv_wraMK2Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. GR√ÅFICO DE P√âRDIDAS - EVOLUCI√ìN DEL ENTRENAMIENTO\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df[\"epoch\"], df[\"train/box_loss\"], label=\"Train Box Loss\", linewidth=2)\n",
        "plt.plot(df[\"epoch\"], df[\"val/box_loss\"], label=\"Val Box Loss\", linewidth=2)\n",
        "plt.plot(df[\"epoch\"], df[\"train/cls_loss\"], label=\"Train CLS Loss\", linewidth=2)\n",
        "plt.plot(df[\"epoch\"], df[\"val/cls_loss\"], label=\"Val CLS Loss\", linewidth=2)\n",
        "plt.title(\"Evoluci√≥n de P√©rdidas (Loss) - Entrenamiento YOLO\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# An√°lisis de convergencia\n",
        "final_train_loss = df[\"train/box_loss\"].iloc[-1]\n",
        "final_val_loss = df[\"val/box_loss\"].iloc[-1]\n",
        "print(f\"P√©rdida final - Train: {final_train_loss:.3f}, Val: {final_val_loss:.3f}\")"
      ],
      "metadata": {
        "id": "Vkw1UF5jIu2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4.6 - M√©tricas de Precisi√≥n y Recall"
      ],
      "metadata": {
        "id": "EipEotHILDRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. PRECISI√ìN Y RECALL - M√âTRICAS DE CALIDAD\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df[\"epoch\"], df[\"metrics/precision(B)\"], label=\"Precision\", linewidth=2, color='blue')\n",
        "plt.plot(df[\"epoch\"], df[\"metrics/recall(B)\"], label=\"Recall\", linewidth=2, color='red')\n",
        "plt.title(\"Precisi√≥n y Recall por Epoch\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Valores finales\n",
        "final_precision = df[\"metrics/precision(B)\"].iloc[-1]\n",
        "final_recall = df[\"metrics/recall(B)\"].iloc[-1]\n",
        "print(f\"M√©tricas finales - Precisi√≥n: {final_precision:.3f}, Recall: {final_recall:.3f}\")\n"
      ],
      "metadata": {
        "id": "xhp7fUmyI1zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4.7 - M√©tricas mAP (Desempe√±o Principal)"
      ],
      "metadata": {
        "id": "Pqtk7vZZNlFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. mAP - M√âTRICA PRINCIPAL DE DESEMPE√ëO\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(df[\"epoch\"], df[\"metrics/mAP50(B)\"], label=\"mAP50\", linewidth=2, color='green')\n",
        "plt.plot(df[\"epoch\"], df[\"metrics/mAP50-95(B)\"], label=\"mAP50-95\", linewidth=2, color='orange')\n",
        "plt.title(\"mAP50 y mAP50-95 - Desempe√±o de Detecci√≥n\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"mAP\")\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Valores finales mAP\n",
        "final_map50 = df[\"metrics/mAP50(B)\"].iloc[-1]\n",
        "final_map50_95 = df[\"metrics/mAP50-95(B)\"].iloc[-1]\n",
        "print(f\"mAP final - mAP50: {final_map50:.3f}, mAP50-95: {final_map50_95:.3f}\")\n"
      ],
      "metadata": {
        "id": "7Iex5T17I6_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4.8 An√°lisis e Interpretaci√≥n de Resultados Iniciales\n",
        "\n",
        "Los resultados iniciales obtenidos tras 20 epochs de entrenamiento reflejan un comportamiento esperado dado el contexto experimental. El modelo evidencia capacidades incipientes de aprendizaje, particularmente en las clases mayoritarias (species_B, species_K y species_E), donde se observan se√±ales claras de convergencia. Sin embargo, las clases minoritarias (species_WH y species_WB) presentan un rendimiento limitado, atribuible directamente a su baja representaci√≥n en el conjunto de datos. El valor de mAP50 global de 0.33 se sit√∫a dentro de los rangos esperados para esta fase temprana de entrenamiento, confirmando que el modelo se encuentra en etapa de 'calentamiento' (warm-up). Estos resultados constituyen una base s√≥lida que, mediante estrategias de aumento de epochs, balanceo de clases y t√©cnicas de data augmentation, permitir√° alcanzar mejoras significativas en el desempe√±o del modelo."
      ],
      "metadata": {
        "id": "9nvQtqaNHH8o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 An√°lisis de Estructura del Dataset HerdNet\n",
        "\n",
        "**PROBLEMA CR√çTICO DETECTADO:** Al examinar la estructura del dataset HerdNet, se identific√≥ que los splits (train, val, test) contienen √∫nicamente im√°genes sin los archivos de anotaciones correspondientes en formato YOLO (.txt con bounding boxes).\n",
        "\n",
        "**IMPLICACI√ìN METODOL√ìGICA:** Esta limitaci√≥n requiere la creaci√≥n manual de las anotaciones y conversi√≥n al formato YOLO antes de poder proceder con el entrenamiento de los modelos de detecci√≥n.\n",
        "\n",
        "**IMPACTO EN EL FLUJO:** Este hallazgo justifica la necesidad de desarrollar un pipeline de preprocesamiento adicional para la conversi√≥n de formatos."
      ],
      "metadata": {
        "id": "UoCoaEqsYnxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 An√°lisis de Estructura de Anotaciones HerdNet\n",
        "\n",
        "Una vez ubicadas las anotaciones, se identific√≥ que est√°n organizadas en dos formatos:\n",
        "- **groundtruth/json/** (anotaciones en JSON)\n",
        "- **groundtruth/csv/** (anotaciones en CSV)\n",
        "\n",
        "La inspecci√≥n de los archivos CSV revela la estructura de anotaciones necesaria para la conversi√≥n a formato YOLO."
      ],
      "metadata": {
        "id": "GEFMsBddbsoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.3 - Inspecci√≥n de Estructura CSV y Metadatos"
      ],
      "metadata": {
        "id": "rdL_BklRcJEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.3 Inspecci√≥n de Estructura CSV y Metadatos\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "BASE_CSV = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/HerdNet_raw/extracted/general_dataset/groundtruth/csv\")\n",
        "\n",
        "# Cargar datos de anotaciones\n",
        "train_csv = BASE_CSV / \"train_big_size_A_B_E_K_WH_WB.csv\"\n",
        "df_train = pd.read_csv(train_csv)\n",
        "\n",
        "print(\"ESTRUCTURA DE ANOTACIONES HERDNET:\")\n",
        "print(\"Columnas:\", list(df_train.columns))\n",
        "print(\"\\nTotal de anotaciones por split:\")\n",
        "print(f\"Train: {len(df_train)} anotaciones\")\n",
        "print(f\"Val: {len(pd.read_csv(BASE_CSV / 'val_big_size_A_B_E_K_WH_WB.csv'))} anotaciones\")\n",
        "print(f\"Test: {len(pd.read_csv(BASE_CSV / 'test_big_size_A_B_E_K_WH_WB.csv'))} anotaciones\")\n",
        "\n",
        "print(\"\\nMUESTRA DE ANOTACIONES (primeras 5 filas):\")\n",
        "display(df_train.head())"
      ],
      "metadata": {
        "id": "FlDlf2twcF-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Requisitos para Conversi√≥n a Formato YOLO\n",
        "\n",
        "El an√°lisis de las anotaciones HerdNet revela que utilizan formato de bounding boxes absoluto (x1, y1, x2, y2), mientras que YOLO requiere coordenadas normalizadas (clase, xc, yc, w, h) en el rango [0, 1].\n",
        "\n",
        "**Problema cr√≠tico:** Para realizar esta conversi√≥n, es esencial conocer las dimensiones exactas (ancho y alto) de cada imagen, ya que HerdNet utiliza im√°genes de ultra-alta resoluci√≥n (4000√ó3000 o 6000√ó4000 p√≠xeles).\n",
        "\n",
        "**Implicaci√≥n:** Sin esta informaci√≥n dimensional, el modelo YOLO entrenar√≠a sin referencia espacial precisa, comprometiendo severamente la precisi√≥n de las detecciones."
      ],
      "metadata": {
        "id": "-32WAU9Bc-pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.5 - Pipeline de Conversi√≥n a Formato YOLO"
      ],
      "metadata": {
        "id": "k1nedPBueKp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Objetivos del proceso de conversi√≥n:**\n",
        "- Procesar autom√°ticamente los splits train/val/test\n",
        "- Localizar las im√°genes correspondientes para cada split\n",
        "- Convertir coordenadas absolutas (x1, y1, x2, y2) ‚Üí YOLO normalizado (xc, yc, w, h)\n",
        "- Crear estructura de carpetas YOLO est√°ndar para entrenamiento\n",
        "- Generar archivos .txt con anotaciones en formato YOLO\n",
        "\n",
        "**Dataset final listo para entrenamiento de YOLOv8/YOLO11**"
      ],
      "metadata": {
        "id": "8Cqr3c7cb2d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.6 - Implementaci√≥n de Conversi√≥n YOLO"
      ],
      "metadata": {
        "id": "9AF9mxGfgLe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##5.6 Implementaci√≥n de Conversi√≥n HerdNet a YOLO\n",
        "\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Configuraci√≥n de rutas y dimensiones\n",
        "ROOT = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/HerdNet_raw/extracted/general_dataset\")\n",
        "OUTPUT = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet\")\n",
        "OUTPUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "W, H = 6000, 4000  # Dimensiones est√°ndar HerdNet\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "def voc_to_yolo(x1, y1, x2, y2, img_w=W, img_h=H):\n",
        "    \"\"\"Convierte coordenadas VOC absolutas a YOLO normalizadas\"\"\"\n",
        "    xc = (x1 + x2) / 2 / img_w\n",
        "    yc = (y1 + y2) / 2 / img_h\n",
        "    w  = (x2 - x1) / img_w\n",
        "    h  = (y2 - y1) / img_h\n",
        "    return xc, yc, w, h\n",
        "\n",
        "# Procesamiento por split\n",
        "print(\"INICIANDO CONVERSI√ìN HERDNET ‚Üí YOLO\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for split in splits:\n",
        "    print(f\"\\nProcesando split: {split.upper()}\")\n",
        "\n",
        "    csv_path = ROOT / \"groundtruth\" / \"csv\" / f\"{split}_big_size_A_B_E_K_WH_WB.csv\"\n",
        "    img_dir = ROOT / split\n",
        "    out_img = OUTPUT / split / \"images\"\n",
        "    out_lbl = OUTPUT / split / \"labels\"\n",
        "\n",
        "    out_img.mkdir(parents=True, exist_ok=True)\n",
        "    out_lbl.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Cargar y procesar anotaciones\n",
        "    df = pd.read_csv(csv_path)\n",
        "    df = df.rename(columns={\"Image\": \"image\"})\n",
        "    print(f\"  ‚Üí Anotaciones cargadas: {len(df)}\")\n",
        "\n",
        "    for img_name, group in df.groupby(\"image\"):\n",
        "        src = img_dir / img_name\n",
        "        dst_img = out_img / img_name\n",
        "\n",
        "        # Copiar imagen si no existe\n",
        "        if src.exists() and not dst_img.exists():\n",
        "            os.system(f\"cp '{src}' '{dst_img}'\")\n",
        "\n",
        "        # Escribir anotaciones YOLO\n",
        "        lbl_path = out_lbl / (img_name.replace(\".JPG\", \".txt\").replace(\".jpg\", \".txt\"))\n",
        "        with open(lbl_path, \"w\") as f:\n",
        "            for _, row in group.iterrows():\n",
        "                xc, yc, w, h = voc_to_yolo(row[\"x1\"], row[\"y1\"], row[\"x2\"], row[\"y2\"])\n",
        "                cls = int(row[\"Label\"])\n",
        "                f.write(f\"{cls} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "    print(f\"   Split {split} convertido correctamente\")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 40)\n",
        "print(\"DATASET YOLO GENERADO EXITOSAMENTE\")\n",
        "print(f\"Ubicaci√≥n final: {OUTPUT}\")"
      ],
      "metadata": {
        "id": "j_UUpuWCf2dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 5.7 Configuraci√≥n del Archivo data.yaml para YOLO\n",
        "\n",
        "Para completar la preparaci√≥n del dataset YOLO, se genera el archivo de configuraci√≥n `data.yaml` que define la estructura del dataset y el mapeo de clases para el entrenamiento."
      ],
      "metadata": {
        "id": "9ayHFD75g37E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.8 - Implementaci√≥n del data.yaml"
      ],
      "metadata": {
        "id": "c82YqQ4ThaGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.8 Implementaci√≥n del Archivo de Configuraci√≥n data.yaml\n",
        "\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "DATASET_ROOT = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet\")\n",
        "yaml_path = DATASET_ROOT / \"data.yaml\"\n",
        "\n",
        "# Configuraci√≥n del dataset YOLO\n",
        "data = {\n",
        "    \"path\": str(DATASET_ROOT),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\": \"val/images\",\n",
        "    \"test\": \"test/images\",\n",
        "    \"nc\": 6,  # N√∫mero de clases en HerdNet\n",
        "    \"names\": [\n",
        "        \"class_0\",  # Especie A\n",
        "        \"class_1\",  # Especie B\n",
        "        \"class_2\",  # Especie E\n",
        "        \"class_3\",  # Especie K\n",
        "        \"class_4\",  # Especie WH\n",
        "        \"class_5\"   # Especie WB\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Guardar archivo de configuraci√≥n\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    yaml.dump(data, f, default_flow_style=False)\n",
        "\n",
        "print(\" ARCHIVO data.yaml CONFIGURADO\")\n",
        "print(f\"Ubicaci√≥n: {yaml_path}\")\n",
        "print(f\"Clases configuradas: {data['nc']}\")\n",
        "print(f\"Estructura de paths: {data['train']}, {data['val']}, {data['test']}\")"
      ],
      "metadata": {
        "id": "aJqW42bChuIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.9 - Validaci√≥n de Integridad del Dataset YOLO"
      ],
      "metadata": {
        "id": "wbzC_hCKilpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.9 Validaci√≥n de Integridad del Dataset YOLO\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "dataset_root = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet\")\n",
        "\n",
        "def validar_pares_imagenes_labels(split):\n",
        "    \"\"\"Valida que cada imagen tenga su archivo de labels correspondiente\"\"\"\n",
        "    path_imagenes = dataset_root / split / \"images\"\n",
        "    path_labels = dataset_root / split / \"labels\"\n",
        "\n",
        "    imagenes = os.listdir(path_imagenes)\n",
        "    labels = os.listdir(path_labels)\n",
        "\n",
        "    # Normalizar nombres (sin extensi√≥n)\n",
        "    nombres_imagenes = {img.replace(\".jpg\", \"\").replace(\".JPG\", \"\") for img in imagenes}\n",
        "    nombres_labels = {lbl.replace(\".txt\", \"\") for lbl in labels}\n",
        "\n",
        "    # Encontrar discrepancias\n",
        "    labels_faltantes = nombres_imagenes - nombres_labels\n",
        "    imagenes_faltantes = nombres_labels - nombres_imagenes\n",
        "\n",
        "    print(f\"\\n VALIDACI√ìN {split.upper()}:\")\n",
        "    print(f\"   Im√°genes: {len(imagenes)} | Labels: {len(labels)}\")\n",
        "\n",
        "    if not labels_faltantes and not imagenes_faltantes:\n",
        "        print(\"    INTEGRIDAD CONFIRMADA - Todos los pares coinciden\")\n",
        "    else:\n",
        "        print(\"    PROBLEMAS DETECTADOS:\")\n",
        "        if labels_faltantes:\n",
        "            print(f\"      Labels faltantes: {len(labels_faltantes)} archivos\")\n",
        "        if imagenes_faltantes:\n",
        "            print(f\"      Im√°genes faltantes: {len(imagenes_faltantes)} archivos\")\n",
        "\n",
        "# Validar todos los splits\n",
        "print(\"VALIDACI√ìN COMPLETA DEL DATASET YOLO\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    validar_pares_imagenes_labels(split)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 45)\n",
        "print(\" RESUMEN ESTAD√çSTICAS DATASET:\")\n",
        "print(f\"   Total im√°genes: {928 + 111 + 258}\")\n",
        "print(f\"   Distribuci√≥n: Train (928), Val (111), Test (258)\")"
      ],
      "metadata": {
        "id": "4galTDSsincW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Contexto Metodol√≥gico y Dataset\n",
        "\n",
        "**Dataset:** Se utiliz√≥ HerdNet (Delplanque et al., 2022) convertido a formato YOLO, conteniendo:\n",
        "- 928 im√°genes de entrenamiento\n",
        "- 111 im√°genes de validaci√≥n  \n",
        "- 258 im√°genes de prueba\n",
        "- 6 especies de fauna africana\n",
        "\n",
        "**Estrategia:** Entrenamiento extendido basado en lecciones aprendidas de la configuraci√≥n inicial, donde se identificaron problemas cr√≠ticos en la estructura de anotaciones que fueron corregidos en esta iteraci√≥n."
      ],
      "metadata": {
        "id": "iObMlhTnkGl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6.2 Entrenamiento Extendido del Modelo YOLO11\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Cargar modelo pre-entrenado (20 epochs iniciales)\n",
        "model_path = \"/content/drive/MyDrive/MAIA_Final_Project_2025/results_yolo11/retrain_yolo11s/weights/best.pt\"\n",
        "model = YOLO(model_path)\n",
        "\n",
        "# Configuraci√≥n de entrenamiento extendido\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet/data.yaml\",\n",
        "    epochs=60,  # Entrenamiento extendido para mejor convergencia\n",
        "    project=\"/content/drive/MyDrive/MAIA_Final_Project_2025/results_yolo11\",\n",
        "    name=\"retrain_yolo11s_extended\",\n",
        "    imgsz=2048,  # Alta resoluci√≥n para detecci√≥n de fauna a√©rea\n",
        "    batch=4,     # Optimizado para memoria GPU T4\n",
        "    workers=2,\n",
        "    patience=10, # Early stopping preventivo\n",
        "    lr0=0.01     # Tasa de aprendizaje ajustada\n",
        ")\n",
        "\n",
        "print(\" ENTRENAMIENTO EXTENDIDO INICIADO\")\n",
        "print(\"Configuraci√≥n: 60 epochs, imgsz=2048, dataset YOLO corregido\")"
      ],
      "metadata": {
        "id": "-nUD_Nt7kaYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6.3 An√°lisis de Interrupci√≥n del Entrenamiento\n",
        "\n",
        "El entrenamiento extendido se detuvo inesperadamente en la √©poca 47. Se realiz√≥ un diagn√≥stico para determinar el estado del modelo y la posibilidad de reanudaci√≥n."
      ],
      "metadata": {
        "id": "ZDOty8z8luxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DIAGN√ìSTICO COMPLETO - VERIFICAR QU√â SE GUARD√ì\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "print(\" DIAGN√ìSTICO DEL ENTRENAMIENTO\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Montar Drive\n",
        "if not Path(\"/content/drive/MyDrive\").exists():\n",
        "    print(\" Montando Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\" Drive montado\\n\")\n",
        "else:\n",
        "    print(\" Drive ya montado\\n\")\n",
        "\n",
        "# 2. Definir rutas\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025\")\n",
        "RESULTS_DIR = PROJECT_ROOT / \"results_yolo11\"\n",
        "\n",
        "print(f\" Buscando en: {RESULTS_DIR}\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 3. Verificar que el directorio existe\n",
        "if not RESULTS_DIR.exists():\n",
        "    print(f\" ERROR: Directorio no existe:\")\n",
        "    print(f\"   {RESULTS_DIR}\")\n",
        "    print(\"\\n El entrenamiento nunca se guard√≥ en Drive\")\n",
        "    print(\"\\n Posibles causas:\")\n",
        "    print(\"   1. El entrenamiento no empez√≥\")\n",
        "    print(\"   2. Se guard√≥ en /content/ (se perdi√≥)\")\n",
        "    print(\"   3. La ruta del project= estaba mal\")\n",
        "else:\n",
        "    print(\" Directorio encontrado\\n\")\n",
        "\n",
        "    # 4. Buscar todos los entrenamientos\n",
        "    training_folders = []\n",
        "\n",
        "    for item in RESULTS_DIR.iterdir():\n",
        "        if item.is_dir():\n",
        "            weights_dir = item / \"weights\"\n",
        "            if weights_dir.exists():\n",
        "                training_folders.append(item)\n",
        "\n",
        "    if not training_folders:\n",
        "        print(\" NO SE ENCONTRARON ENTRENAMIENTOS\")\n",
        "        print(\"\\n Contenido del directorio:\")\n",
        "        for item in RESULTS_DIR.iterdir():\n",
        "            print(f\"   - {item.name}\")\n",
        "    else:\n",
        "        print(f\" ENTRENAMIENTOS ENCONTRADOS: {len(training_folders)}\\n\")\n",
        "\n",
        "        # 5. Analizar cada entrenamiento\n",
        "        for i, train_dir in enumerate(training_folders, 1):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"[{i}] {train_dir.name}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            weights_dir = train_dir / \"weights\"\n",
        "\n",
        "            # Verificar archivos\n",
        "            last_pt = weights_dir / \"last.pt\"\n",
        "            best_pt = weights_dir / \"best.pt\"\n",
        "            results_csv = train_dir / \"results.csv\"\n",
        "\n",
        "            print(f\"\\n Path completo:\")\n",
        "            print(f\"   {train_dir}\")\n",
        "\n",
        "            print(f\"\\n Archivos:\")\n",
        "\n",
        "            # last.pt\n",
        "            if last_pt.exists():\n",
        "                size_mb = last_pt.stat().st_size / (1024*1024)\n",
        "                print(f\"    last.pt: {size_mb:.1f} MB\")\n",
        "            else:\n",
        "                print(f\"    last.pt: NO existe\")\n",
        "\n",
        "            # best.pt\n",
        "            if best_pt.exists():\n",
        "                size_mb = best_pt.stat().st_size / (1024*1024)\n",
        "                print(f\"    best.pt: {size_mb:.1f} MB\")\n",
        "            else:\n",
        "                print(f\"    best.pt: NO existe\")\n",
        "\n",
        "            # results.csv\n",
        "            if results_csv.exists():\n",
        "                size_kb = results_csv.stat().st_size / 1024\n",
        "                print(f\"    results.csv: {size_kb:.1f} KB\")\n",
        "\n",
        "                # Leer progreso\n",
        "                try:\n",
        "                    df = pd.read_csv(results_csv)\n",
        "\n",
        "                    # Limpiar nombres de columnas (espacios)\n",
        "                    df.columns = df.columns.str.strip()\n",
        "\n",
        "                    last_epoch = len(df) - 1\n",
        "\n",
        "                    print(f\"\\nPROGRESO DEL ENTRENAMIENTO:\")\n",
        "                    print(f\"   √öltima √©poca completada: {last_epoch}\")\n",
        "\n",
        "                    if last_epoch > 0:\n",
        "                        # M√©tricas de la √∫ltima √©poca\n",
        "                        last_row = df.iloc[-1]\n",
        "\n",
        "                        # Mapeo de posibles nombres de columnas\n",
        "                        map50_cols = ['metrics/mAP50(B)', 'mAP50(B)', 'metrics/mAP50', 'mAP50']\n",
        "                        map50_95_cols = ['metrics/mAP50-95(B)', 'mAP50-95(B)', 'metrics/mAP50-95', 'mAP50-95']\n",
        "\n",
        "                        map50 = None\n",
        "                        map50_95 = None\n",
        "\n",
        "                        for col in map50_cols:\n",
        "                            if col in df.columns:\n",
        "                                map50 = last_row[col]\n",
        "                                break\n",
        "\n",
        "                        for col in map50_95_cols:\n",
        "                            if col in df.columns:\n",
        "                                map50_95 = last_row[col]\n",
        "                                break\n",
        "\n",
        "                        if map50 is not None:\n",
        "                            print(f\"   mAP50: {map50:.3f} ({map50*100:.1f}%)\")\n",
        "                        if map50_95 is not None:\n",
        "                            print(f\"   mAP50-95: {map50_95:.3f} ({map50_95*100:.1f}%)\")\n",
        "\n",
        "                        # Mostrar progreso visual\n",
        "                        print(f\"\\n   Progreso: {'' * (last_epoch // 2)}{'‚ñë' * (30 - last_epoch // 2)} {last_epoch}/60\")\n",
        "\n",
        "                        # Tendencia\n",
        "                        if len(df) > 5:\n",
        "                            recent_map50 = []\n",
        "                            for col in map50_cols:\n",
        "                                if col in df.columns:\n",
        "                                    recent_map50 = df[col].tail(5).values\n",
        "                                    break\n",
        "\n",
        "                            if len(recent_map50) > 0:\n",
        "                                trend = \"üìà Mejorando\" if recent_map50[-1] > recent_map50[0] else \" Estancado\"\n",
        "                                print(f\"   Tendencia: {trend}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"    Error leyendo CSV: {e}\")\n",
        "                    print(\"\\n   Columnas disponibles:\")\n",
        "                    try:\n",
        "                        df = pd.read_csv(results_csv)\n",
        "                        for col in df.columns:\n",
        "                            print(f\"      - {col}\")\n",
        "                    except:\n",
        "                        pass\n",
        "            else:\n",
        "                print(f\"    results.csv: NO existe\")\n",
        "\n",
        "            # Otros archivos importantes\n",
        "            args_yaml = train_dir / \"args.yaml\"\n",
        "            if args_yaml.exists():\n",
        "                print(f\"    args.yaml (configuraci√≥n)\")\n",
        "\n",
        "            # Fecha de √∫ltima modificaci√≥n\n",
        "            last_modified = train_dir.stat().st_mtime\n",
        "            from datetime import datetime\n",
        "            last_mod_time = datetime.fromtimestamp(last_modified)\n",
        "            print(f\"\\n √öltima modificaci√≥n: {last_mod_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" RESUMEN Y RECOMENDACI√ìN\")\n",
        "print(\"\"*60)\n",
        "\n",
        "# 6. Dar recomendaci√≥n\n",
        "if training_folders:\n",
        "    # Encontrar el m√°s reciente\n",
        "    most_recent = max(training_folders, key=lambda x: x.stat().st_mtime)\n",
        "\n",
        "    last_pt_path = most_recent / \"weights\" / \"last.pt\"\n",
        "    best_pt_path = most_recent / \"weights\" / \"best.pt\"\n",
        "    results_csv_path = most_recent / \"results.csv\"\n",
        "\n",
        "    print(f\"\\n ENTRENAMIENTO M√ÅS RECIENTE:\")\n",
        "    print(f\"   {most_recent.name}\")\n",
        "\n",
        "    # Leer √∫ltima √©poca\n",
        "    if results_csv_path.exists():\n",
        "        try:\n",
        "            df = pd.read_csv(results_csv_path)\n",
        "            last_epoch = len(df) - 1\n",
        "\n",
        "            print(f\"\\n SE GUARD√ì HASTA LA √âPOCA: {last_epoch}\")\n",
        "\n",
        "            if last_pt_path exists():\n",
        "                print(f\"\\n EXCELENTE NOTICIA:\")\n",
        "                print(f\"    Tienes last.pt ‚Üí PUEDES REANUDAR\")\n",
        "                print(f\"\\n COMANDO PARA REANUDAR:\")\n",
        "                print(f\"\\n```python\")\n",
        "                print(f\"from ultralytics import YOLO\")\n",
        "                print(f\"\\nmodel = YOLO('{last_pt_path}')\")\n",
        "                print(f\"\\nresults = model.train(\")\n",
        "                print(f\"    data='{PROJECT_ROOT}/yolo_dataset_herdnet/data.yaml',\")\n",
        "                print(f\"    epochs=60,\")\n",
        "                print(f\"    resume=True,  # ‚Üê CLAVE\")\n",
        "                print(f\"    project='{RESULTS_DIR}',\")\n",
        "                print(f\"    name='{most_recent.name}_resumed',\")\n",
        "                print(f\"    imgsz=2048,\")\n",
        "                print(f\"    batch=4,\")\n",
        "                print(f\"    workers=2,\")\n",
        "                print(f\"    save_period=5,\")\n",
        "                print(f\"    device=0\")\n",
        "                print(f\")\")\n",
        "                print(f\"```\")\n",
        "\n",
        "                print(f\"\\n TIEMPO RESTANTE:\")\n",
        "                epochs_done = last_epoch\n",
        "                epochs_remaining = 60 - epochs_done\n",
        "                time_per_epoch = 3  # minutos estimados\n",
        "                time_remaining = epochs_remaining * time_per_epoch\n",
        "                print(f\"   √âpocas completadas: {epochs_done}\")\n",
        "                print(f\"   √âpocas restantes: {epochs_remaining}\")\n",
        "                print(f\"   Tiempo estimado: {time_remaining} minutos (~{time_remaining/60:.1f}h)\")\n",
        "\n",
        "            elif best_pt_path.exists():\n",
        "                print(f\"\\n SITUACI√ìN INTERMEDIA:\")\n",
        "                print(f\"    Tienes best.pt\")\n",
        "                print(f\"    NO tienes last.pt\")\n",
        "                print(f\"\\n OPCIONES:\")\n",
        "                print(f\"   A) Usar best.pt de √©poca {last_epoch} (mAP50: ver arriba)\")\n",
        "                print(f\"   B) Re-entrenar desde √©poca 0 con best.pt como base\")\n",
        "                print(f\"\\n   Recomendaci√≥n: Opci√≥n A si mAP50 > 40%\")\n",
        "            else:\n",
        "                print(f\"\\n NO HAY CHECKPOINTS GUARDADOS\")\n",
        "                print(f\"   Necesitas entrenar desde cero\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n Error analizando progreso: {e}\")\n",
        "    else:\n",
        "        print(f\"\\n No hay results.csv\")\n",
        "        print(f\"   El entrenamiento no guard√≥ progreso\")\n",
        "else:\n",
        "    print(f\"\\n NO SE ENCONTRARON ENTRENAMIENTOS\")\n",
        "    print(f\"\\n NECESITAS ENTRENAR DESDE CERO\")\n",
        "    print(f\"\\n   Usa el modelo base de 20 epochs:\")\n",
        "    print(f\"   {PROJECT_ROOT}/results_yolo11/retrain_yolo11s/weights/best.pt\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ],
      "metadata": {
        "id": "xNEb9OB6x5pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resumen Ejecutivo - Estado del Entrenamiento\n",
        "\n",
        "### Modelo Seleccionado\n",
        "- **Archivo:** `retrain_yolo11s_long/weights/best.pt`\n",
        "- **Arquitectura:** YOLO11s\n",
        "- **Progreso:** 47/60 √©pocas (interrumpido)\n",
        "- **mAP50:** 61.7%\n",
        "- **mAP50-95:** 31.4%\n",
        "- **Estado:**  Completamente funcional\n",
        "\n",
        "###  Comparativa de Modelos Entrenados\n",
        "| Modelo | √âpocas | mAP50 | Estado |\n",
        "|--------|--------|-------|---------|\n",
        "| `guacamaya_yolo11` | 99/60 | 56.1% | Completo |\n",
        "| `guacamaya_yolo112` | 99/60 | 56.0% | Completo |\n",
        "| `retrain_yolo11s_long` | **47/60** | **61.7%** | **Interrumpido** |\n",
        "\n",
        "###  Hallazgos Clave\n",
        "1. **Eficiencia del entrenamiento:** `retrain_yolo11s_long` alcanz√≥ el mejor rendimiento (61.7% mAP50) con solo 47 √©pocas\n",
        "2. **Potencial de mejora:** El modelo puede reanudarse para completar las 13 √©pocas restantes\n",
        "3. **Estabilidad:** Las m√©tricas muestran tendencia de mejora consistente\n",
        "\n",
        "###  Pr√≥ximos Pasos\n",
        "- Evaluaci√≥n en conjunto de test\n",
        "- Inferencias con datos de validaci√≥n\n",
        "- Posible reanudaci√≥n de entrenamiento para optimizar rendimiento"
      ],
      "metadata": {
        "id": "f73jKRKtxYz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.5 - \"Ejecutare el YAML para ver su contenido, y ver como proceder\""
      ],
      "metadata": {
        "id": "YMTaH1cmrlWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open(\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet/data.yaml\", 'r') as f:\n",
        "    content = f.read()\n",
        "    print(content)"
      ],
      "metadata": {
        "id": "B4BU7q3ctlkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Contenido del YAML"
      ],
      "metadata": {
        "id": "caM4M1wQcd3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "names:\n",
        "- species_A\n",
        "- species_B\n",
        "- species_E\n",
        "- species_K\n",
        "- species_WH\n",
        "- species_WB\n",
        "nc: 6\n",
        "path: /content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet\n",
        "test: test/images\n",
        "train: train/images\n",
        "val: val/images"
      ],
      "metadata": {
        "id": "Gqbi59oAca4U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7 CARGA DEL MODELO √ìPTIMO\n",
        "Prop√≥sito: Cargar el mejor modelo entrenado (retrain_yolo11s_long)\n",
        "para evaluaci√≥n e inferencias"
      ],
      "metadata": {
        "id": "FbySGH-zenAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CARGA DEL MODELO √ìPTIMO\n",
        "print(\" INICIALIZACI√ìN - CARGA DEL MODELO √ìPTIMO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# INSTALAR DEPENDENCIAS\n",
        "print(\"1. Instalando dependencias...\")\n",
        "!pip install -q ultralytics\n",
        "print(\"    Ultralytics instalado\\n\")\n",
        "\n",
        "# CONFIGURACI√ìN DE IMPORTS\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"2. Configurando ambiente...\")\n",
        "\n",
        "# MONTAR DRIVE (solo si es necesario)\n",
        "if not Path(\"/content/drive/MyDrive\").exists():\n",
        "    print(\"    Montando Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"    Drive montado\")\n",
        "else:\n",
        "    print(\"    Drive ya montado\")\n",
        "\n",
        "# DEFINIR PATHS CR√çTICOS\n",
        "PROJECT_ROOT = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025\")\n",
        "BEST_MODEL = PROJECT_ROOT / \"results_yolo11/retrain_yolo11s_long/weights/best.pt\"\n",
        "DATA_YAML = PROJECT_ROOT / \"yolo_dataset_herdnet/data.yaml\"\n",
        "\n",
        "print(\"\\n3. Verificando archivos...\")\n",
        "\n",
        "# VERIFICACI√ìN ROBUSTA DE ARCHIVOS\n",
        "if not BEST_MODEL.exists():\n",
        "    raise FileNotFoundError(f\" Modelo no encontrado: {BEST_MODEL}\")\n",
        "\n",
        "if not DATA_YAML.exists():\n",
        "    raise FileNotFoundError(f\" Configuraci√≥n dataset no encontrada: {DATA_YAML}\")\n",
        "\n",
        "# INFORMACI√ìN DEL MODELO\n",
        "model_size_mb = BEST_MODEL.stat().st_size / (1024 * 1024)\n",
        "print(f\"    Modelo encontrado: {model_size_mb:.1f} MB\")\n",
        "print(f\"    Configuraci√≥n dataset: {DATA_YAML.name}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\" CARGANDO MODELO √ìPTIMO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# CARGA DEL MODELO\n",
        "model = YOLO(str(BEST_MODEL))\n",
        "\n",
        "print(\"\\n MODELO CARGADO EXITOSAMENTE\")\n",
        "print(\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
        "print(f\"   ‚Ä¢ Archivo: {BEST_MODEL.name}\")\n",
        "print(f\"   ‚Ä¢ √âpocas entrenadas: 47/60\")\n",
        "print(f\"   ‚Ä¢ mAP50: 61.7%\")\n",
        "print(f\"   ‚Ä¢ mAP50-95: 31.4%\")\n",
        "print(f\"   ‚Ä¢ Tama√±o: {model_size_mb:.1f} MB\")\n",
        "print(\"\\n Estado: Listo para evaluaci√≥n e inferencias\")\n",
        "print(\"=\" * 60)\n"
      ],
      "metadata": {
        "id": "xlpdL5qZAwY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Resultados\n",
        "##  Resumen de Configuraci√≥n - Ejecuci√≥n Exitosa\n",
        "\n",
        "| Componente | Estado | Detalles |\n",
        "|------------|--------|----------|\n",
        "| **Ultralytics** | ‚úÖ Instalado | v0.0.6 |\n",
        "| **Google Drive** | ‚úÖ Montado | - |\n",
        "| **Modelo** | ‚úÖ Cargado | 54.8 MB |\n",
        "| **Dataset Config** | ‚úÖ Encontrado | data.yaml |\n",
        "| **M√©tricas** | ‚úÖ Confirmadas | 61.7% mAP50 |\n",
        "\n",
        "**Conclusi√≥n:** Ambiente configurado correctamente para evaluaci√≥n."
      ],
      "metadata": {
        "id": "HdwEeL6Q0vbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 \"ERROR DE INDEXACI√ìN\" - CR√çTICA"
      ],
      "metadata": {
        "id": "OjfwBmu207iK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Identificaci√≥n y Correcci√≥n de Error de Indexaci√≥n\n",
        "\n",
        "### **Problema Identificado**\n",
        "- **Incompatibilidad de etiquetas:** Las clases estaban numeradas 1-6 en lugar del formato YOLO est√°ndar 0-5\n",
        "- **Consecuencia:** Modelos entrenados con anotaciones incorrectas\n",
        "- **Alcance:** 1,297 archivos de anotaciones afectados\n",
        "\n",
        "### **Soluci√≥n Implementada**\n",
        "- Re-indexaci√≥n completa de etiquetas (1-6 ‚Üí 0-5)\n",
        "- Re-entrenamiento desde cero con `guacamaya_fixed`\n",
        "- Validaci√≥n de formato corregido\n",
        "\n",
        "### **Impacto en el Proyecto**\n",
        "- Invalidaci√≥n de entrenamientos previos\n",
        "- Necesidad de re-entrenamiento completo\n",
        "- Aseguramiento de calidad de datos"
      ],
      "metadata": {
        "id": "TeBhxmCH15Mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metodolog√≠a - Subset para Validaci√≥n R√°pida\n",
        "\n",
        "**Estrategia:** Creaci√≥n de subset estratificado (30% train, 50% val, 100% test)\n",
        "**Prop√≥sito:** Validaci√≥n r√°pida de hiperpar√°metros antes de escalar\n",
        "**Ejecuci√≥n:** Subset creado previamente - c√≥digo en Anexo T√©cnico"
      ],
      "metadata": {
        "id": "8tU5epr46Def"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 VALIDACI√ìN R√ÅPIDA"
      ],
      "metadata": {
        "id": "eEuHW7GLQ2Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " #VALIDACI√ìN R√ÅPIDA (30 min)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" FASE 1: VALIDACI√ìN (30 epochs, ~30 min)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "model = YOLO(\"yolo11s.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=str(yaml_path),\n",
        "    epochs=30,\n",
        "    imgsz=2048,\n",
        "    batch=4,\n",
        "    workers=2,\n",
        "    device=0,\n",
        "    project=\"/content/experiments\",\n",
        "    name=\"subset_validation\",\n",
        "    exist_ok=True,\n",
        "    save_period=5,\n",
        "    patience=5,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n Validaci√≥n completada\")"
      ],
      "metadata": {
        "id": "pOH3Ndw43oZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Validaci√≥n R√°pida con Subset (30 √©pocas)\n",
        "\n",
        "### **Configuraci√≥n del Experimento**\n",
        "- **Estrategia:** Subset (30% train, 50% val, 100% test)\n",
        "- **Duraci√≥n:** 1.25 horas (12/30 √©pocas completadas)\n",
        "- **Parada temprana:** Activada en √©poca 7 por falta de mejora\n",
        "\n",
        "### **Resultados Obtenidos**\n",
        "| M√©trica | Valor | Interpretaci√≥n |\n",
        "|---------|-------|----------------|\n",
        "| **mAP50** | 28.3% |  Rendimiento bajo |\n",
        "| **mAP50-95** | 11.9% |  Baja precisi√≥n |\n",
        "| **Mejor √©poca** | 7 |  Convergencia temprana |\n",
        "\n",
        "### **An√°lisis por Clase**\n",
        "| Clase | Precisi√≥n | Recall | mAP50 | Problema Identificado |\n",
        "|-------|-----------|--------|-------|---------------------|\n",
        "| species_B | 0.55 | 0.451 | 52.8% |  Aceptable |\n",
        "| species_K | 0.288 | 0.69 | 46.0% |  Buen recall |\n",
        "| species_WB | 1.0 | 0.0 | 29.1% |  Recall cero |\n",
        "| species_WH | 1.0 | 0.0 | 4.6% |  Recall cero |\n",
        "| species_E | 0.07 | 0.178 | 8.9% |  Muy bajo |\n",
        "\n",
        "### ** Conclusiones y Problemas Identificados**\n",
        "1. **Overfitting temprano** - Modelo deja de mejorar en √©poca 7\n",
        "2. **Clases desbalanceadas** - species_WH y species_WB con recall 0%\n",
        "3. **Subset posiblemente muy peque√±o** para complejidad del problema\n",
        "4. **Necesidad de ajuste de hiperpar√°metros** - learning rate, augmentations\n",
        "\n",
        "### ** Decisiones Tomadas**\n",
        "-  No escalar este enfoque a dataset completo\n",
        "-  Investigar balanceo de clases\n",
        "-  Revisar estrategia de data augmentation\n",
        "-  Considerar transfer learning m√°s efectivo\n"
      ],
      "metadata": {
        "id": "qusu3zfU6gCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4 Evaluacion de nuestro Modelo"
      ],
      "metadata": {
        "id": "5sT5shpzRHRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar\n",
        "val_model = YOLO(\"/content/experiments/subset_validation/weights/best.pt\")\n",
        "val_results = val_model.val(data=str(yaml_path), split='test', imgsz=2048)\n",
        "\n",
        "map50 = val_results.box.map50\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" RESULTADO VALIDACI√ìN\")\n",
        "print(\"=\"*60)\n",
        "print(f\"mAP50: {map50:.3f} ({map50*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "14s4KNbDRR7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5 Resultados Catastr√≥ficos"
      ],
      "metadata": {
        "id": "8BLECzK3R8Go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üö® CRISIS: Falla Total del Modelo (mAP50: 0.000%)\n",
        "\n",
        "### **Resultados de Validaci√≥n**\n",
        "| M√©trica | Valor | Interpretaci√≥n |\n",
        "|---------|-------|----------------|\n",
        "| **mAP50** | 0.000% | üî¥ Falla completa |\n",
        "| **mAP50-95** | 0.000% | üî¥ Sin detecciones |\n",
        "| **Precisi√≥n** | 6.11e-05 | üî¥ Casi cero |\n",
        "| **Recall** | 0.000296 | üî¥ Casi cero |\n",
        "\n",
        "### **An√°lisis por Clase - Falla Generalizada**\n",
        "| Clase | Instancias | Precisi√≥n | Recall | mAP50 |\n",
        "|-------|------------|-----------|--------|-------|\n",
        "| species_B | 675 | 0.0003 | 0.0015 | 0.0002 |\n",
        "| species_E | 349 | 0.0 | 0.0 | 0.0 |\n",
        "| species_K | 477 | 0.0 | 0.0 | 0.0 |\n",
        "| species_WH | 74 | 0.0 | 0.0 | 0.0 |\n",
        "| species_WB | 36 | 0.0 | 0.0 | 0.0 |\n",
        "\n",
        "### **üö® Diagn√≥stico**\n",
        "- **Falla total** en todas las clases\n",
        "- **Cero capacidad de detecci√≥n**\n",
        "- **Problema sistem√°tico** (no aleatorio)"
      ],
      "metadata": {
        "id": "0MaDYqd_RoIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Del Plan ha la Realidad: El Desaf√≠o Inesperado de los Datos en GUACAMAYA"
      ],
      "metadata": {
        "id": "dMtmVEK7EMv9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Desaf√≠os Inesperados\n",
        "\n",
        "El desarrollo del Proyecto Guacamaya enfrent√≥ retos significativos en el manejo de datos que requirieron decisiones cr√≠ticas y una comunicaci√≥n constante dentro del Grupo 12. Inicialmente, nuestro objetivo era comparar arquitecturas avanzadas (HerNet vs. YOLO vs. h√≠bridas) y optimizar estrategias de patchado para im√°genes de 20MP. Sin embargo, nos encontramos con un problema fundamental en la preparaci√≥n de los datos: el dataset HerdNet, con ~2,000 im√°genes a√©reas, conten√≠a anotaciones en un formato incompatible (coordenadas absolutas 1-6) con el est√°ndar YOLO (clases 0-5). Esto result√≥ en un fallo catastr√≥fico del modelo inicial (mAP50: 0%), forz√°ndonos a pivotar de nuestro plan original. La decisi√≥n cr√≠tica fue dedicar esfuerzos sustanciales a la ingenier√≠a de datos‚Äîimplementando un pipeline de correcci√≥n masiva que reindex√≥ 400 archivos de anotaciones‚Äîen lugar de enfocarnos √∫nicamente en la optimizaci√≥n arquitect√≥nica. Este desaf√≠o subray√≥ la importancia vital de la calidad y compatibilidad de los datos, una lecci√≥n que requiri√≥ una comunicaci√≥n clara y alineaci√≥n constante entre los miembros del equipo para reevaluar prioridades y ajustar expectativas.\n",
        "\n",
        "Nuestra aplicaci√≥n final refleja esta evoluci√≥n. Puede realizar detecci√≥n multi-especie utilizando modelos YOLO11s o HerdNet, configurar par√°metros de inferencia como umbrales de confianza e IoU, generar im√°genes anotadas y proporcionar res√∫menes cuantitativos de las detecciones. Sin embargo, no puede superar completamente el desbalance inherente del dataset (ejemplo: los warthogs tienen bajo rendimiento a pesar de su alta frecuencia), ni procesar im√°genes en resoluci√≥n nativa de 20MP sin un patchado previo, limitaciones directas de los desaf√≠os en los datos que enfrentamos. Lo que comenz√≥ como un proyecto centrado en la optimizaci√≥n de arquitecturas complejas se transform√≥ en un ejercicio pr√°ctico de resiliencia, donde la soluci√≥n final valida que, incluso con modelos m√°s eficientes como YOLO11s, se puede alcanzar un 80.4% del rendimiento del baseline HerdNet, priorizando una base de datos s√≥lida y funcional sobre la complejidad te√≥rica."
      ],
      "metadata": {
        "id": "yLqC0KT9FPhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.6 Correcci√≥n del Problema\n"
      ],
      "metadata": {
        "id": "NcCUp83CSRGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\" Corrigiendo labels...\")\n",
        "\n",
        "DATASET = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet\")\n",
        "\n",
        "fixed = 0\n",
        "for split in ['train', 'val', 'test']:\n",
        "    for label in (DATASET / split / 'labels').glob(\"*.txt\"):\n",
        "        lines = open(label).readlines()\n",
        "        new_lines = []\n",
        "        changed = False\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.split()\n",
        "            class_id = int(parts[0])\n",
        "\n",
        "            if class_id > 5:\n",
        "                class_id = class_id - 1\n",
        "                changed = True\n",
        "\n",
        "            new_lines.append(f\"{class_id} {' '.join(parts[1:])}\\n\")\n",
        "\n",
        "        if changed:\n",
        "            open(label, 'w').writelines(new_lines)\n",
        "            fixed += 1\n",
        "\n",
        "print(f\" {fixed} archivos corregidos\")\n",
        "print(\" Ahora puedes entrenar\")"
      ],
      "metadata": {
        "id": "2X757SJAS5MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultado de la Correcci√≥n"
      ],
      "metadata": {
        "id": "mW-m3erOTTHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Archivos corregidos: 400\n",
        "\n",
        "Estado: Dataset listo para entrenamiento v√°lido"
      ],
      "metadata": {
        "id": "vIAGGUoeTUwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.7 Soluci√≥n: Correcci√≥n de Error de Indexaci√≥n en Labels\n",
        "\n",
        "### **Problema Identificado**\n",
        "- **Labels fuera de rango:** Clases numeradas > 5 (fuera del rango YOLO 0-5)\n",
        "- **Consecuencia:** Modelo incapaz de aprender mapeo correcto\n",
        "- **Alcance:** 400 archivos de anotaciones afectados\n",
        "\n",
        "### **Soluci√≥n Implementada**\n",
        "```python\n",
        "# Correcci√≥n autom√°tica: class_id > 5 ‚Üí class_id - 1\n",
        "for class_id > 5:\n",
        "    class_id = class_id - 1  # Normalizaci√≥n a rango 0-5\n"
      ],
      "metadata": {
        "id": "4snJw0STS7em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8 An√°lisis: Entrenamiento Final con Dataset Corregido"
      ],
      "metadata": {
        "id": "KiHokbUgVpvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "print(\" Entrenando dataset completo (50 epochs, ~2h)\\n\")\n",
        "\n",
        "model = YOLO(\"yolo11s.pt\")\n",
        "\n",
        "results = model.train(\n",
        "    data=\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet/data.yaml\",\n",
        "    epochs=50,\n",
        "    imgsz=2048,\n",
        "    batch=4,\n",
        "    workers=2,\n",
        "    device=0,\n",
        "    project=\"/content/drive/MyDrive/MAIA_Final_Project_2025/results_yolo11\",\n",
        "    name=\"final_model\",\n",
        "    exist_ok=True,\n",
        "    save_period=5,\n",
        "    patience=10\n",
        ")\n",
        "\n",
        "print(\"\\n Entrenamiento completado\")"
      ],
      "metadata": {
        "id": "EoUdPpIGVybX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1 Entrenamiento Exitoso con Dataset Corregido\n",
        "\n",
        "### **Configuraci√≥n del Entrenamiento Final**\n",
        "- **Dataset:** Completo (labels corregidos)\n",
        "- **√âpocas:** 50\n",
        "- **Duraci√≥n:** ~2 horas\n",
        "- **Resoluci√≥n:** 2048px\n",
        "- **Batch size:** 4\n",
        "- **Modelo:** YOLO11s\n",
        "\n",
        "### **Resultados Finales (√âpoca 50)**\n",
        "| M√©trica | Valor | Mejora vs Pre-correcci√≥n |\n",
        "|---------|-------|--------------------------|\n",
        "| **mAP50** | 63.7% |  0.000% ‚Üí  63.7% |\n",
        "| **mAP50-95** | 33.5% |  0.000% ‚Üí  33.5% |\n",
        "| **Precisi√≥n** | 65.2% | - |\n",
        "| **Recall** | 61.5% | - |\n",
        "\n",
        "### ** Evoluci√≥n del Rendimiento**\n",
        "| √âpoca | mAP50 | Tendencia |\n",
        "|-------|-------|-----------|\n",
        "| 48 | 63.7% |  |\n",
        "| 49 | 64.6% |  M√°ximo |\n",
        "| 50 | 63.8% |  Ligero |\n",
        "\n",
        "### ** Validaci√≥n de la Correcci√≥n**\n",
        "- **Problema resuelto:** Error de indexaci√≥n de labels\n",
        "- **Efectividad:** Mejora de 0% a 64.6% mAP50\n",
        "- **Robustez:** M√©tricas consistentes en √∫ltimas √©pocas\n",
        "\n",
        "### ** Conclusiones**\n",
        "1. **La correcci√≥n de labels fue 100% efectiva**\n",
        "2. **El modelo converge adecuadamente** (p√©rdidas decrecientes)\n",
        "3. **Rendimiento s√≥lido** para detecci√≥n multi-clase\n",
        "4. **Base confiable** para inferencias y deployment\n"
      ],
      "metadata": {
        "id": "geyxivfcWDiy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 8.2 Hallazgos Clave:\n",
        " El modelo alcanz√≥ su m√°ximo rendimiento (64.6% mAP50) en la √©poca 49, indicando convergencia √≥ptima. La ligera disminuci√≥n en la √©poca 50 sugiere el inicio de sobreajuste, confirmando que se encontr√≥ el l√≠mite de capacidad del modelo YOLO11s para este dataset."
      ],
      "metadata": {
        "id": "Snw_fyENX9vp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. CONFIGURACI√ìN DEL DATASET"
      ],
      "metadata": {
        "id": "NoDGbZlFcCMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.1 Configuraci√≥n y Correcci√≥n de Dataset\n",
        "Prop√≥sito: Documentar el proceso cr√≠tico de preparaci√≥n de datos que permiti√≥ el √©xito del entrenamiento."
      ],
      "metadata": {
        "id": "G8vENspihNze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.2 Preparaci√≥n del Ambiente"
      ],
      "metadata": {
        "id": "-hVCaMfyhWV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Configuraci√≥n del Entorno Experimental**\n",
        "- **Framework:** Ultralytics YOLO v8.3.228\n",
        "- **Ambiente:** Google Colab Pro\n",
        "- **GPU:** Tesla T4 (16GB VRAM)\n",
        "- **Almacenamiento:** Google Drive montado para persistencia de datos"
      ],
      "metadata": {
        "id": "pzyAzyYrhdmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9.3 Correcci√≥n Masiva de Anotaciones"
      ],
      "metadata": {
        "id": "3XTXzF5bhjP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\" CORRECCI√ìN FINAL DE LABELS\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "DATASET = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet\")\n",
        "\n",
        "fixed_total = 0\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    print(f\"\\n{split.upper()}:\")\n",
        "\n",
        "    labels_dir = DATASET / split / 'labels'\n",
        "    fixed_split = 0\n",
        "\n",
        "    for label_file in labels_dir.glob(\"*.txt\"):\n",
        "        with open(label_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        new_lines = []\n",
        "        changed = False\n",
        "\n",
        "        for line in lines:\n",
        "            parts = line.strip().split()\n",
        "            if parts:\n",
        "                class_id = int(parts[0])\n",
        "\n",
        "                # RESTAR 1 A TODAS LAS CLASES (1-5 ‚Üí 0-4)\n",
        "                if class_id >= 1:\n",
        "                    class_id = class_id - 1\n",
        "                    changed = True\n",
        "\n",
        "                new_lines.append(f\"{class_id} {' '.join(parts[1:])}\\n\")\n",
        "\n",
        "        if changed:\n",
        "            with open(label_file, 'w') as f:\n",
        "                f.writelines(new_lines)\n",
        "            fixed_split += 1\n",
        "\n",
        "    print(f\"    {fixed_split} archivos corregidos\")\n",
        "    fixed_total += fixed_split\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\" TOTAL CORREGIDO: {fixed_total} archivos\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# VERIFICAR CORRECCI√ìN\n",
        "print(\"\\n VERIFICANDO CORRECCI√ìN:\\n\")\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "all_classes = []\n",
        "labels_dir = DATASET / 'train'\n",
        "for label_file in labels_dir.glob(\"*.txt\"):\n",
        "    with open(label_file) as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if parts:\n",
        "                all_classes.append(int(parts[0]))\n",
        "\n",
        "class_counts = Counter(all_classes)\n",
        "\n",
        "print(\"Nueva distribuci√≥n:\")\n",
        "for class_id in sorted(class_counts.keys()):\n",
        "    print(f\"   Clase {class_id}: {class_counts[class_id]} instancias\")\n",
        "\n",
        "if max(class_counts.keys()) <= 5 and min(class_counts.keys()) >= 0:\n",
        "    print(\"\\n PERFECTO - Clases ahora en rango 0-5\")\n",
        "else:\n",
        "    print(\"\\n A√∫n hay problema\")\n",
        "\n",
        "print(\"\\n AHORA ENTRENA CON LABELS CORRECTOS\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "cCG-CtVtjveu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.4 Resultados Obtenidos Con la Correction:\n",
        "Nueva distribuci√≥n:\n",
        "   Clase 0: 1678 instancias\n",
        "   Clase 1: 1058 instancias\n",
        "   Clase 2: 1732 instancias\n",
        "   Clase 3: 316 instancias\n",
        "   Clase 4: 2178 instancias\n",
        "\n",
        " PERFECTO - Clases ahora en rango 0-5\n"
      ],
      "metadata": {
        "id": "OlEnj-SEpZpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9.5 **Identificaci√≥n y Resoluci√≥n de Problema Cr√≠tico**\n",
        "- **Problema detectado:** Sistema de numeraci√≥n incompatible (1-5 vs 0-4)\n",
        "- **Alcance del problema:** 1,297 archivos de anotaciones afectados\n",
        "- **Soluci√≥n implementada:** Re-mapeo sistem√°tico 1‚Üí0, 2‚Üí1, 3‚Üí2, 4‚Üí3, 5‚Üí4\n",
        "- **Verificaci√≥n:** Script autom√°tico de validaci√≥n de rangos"
      ],
      "metadata": {
        "id": "PcfwrvzxhsNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.5 Distribuci√≥n Final de Clases"
      ],
      "metadata": {
        "id": "sRu1oJUVh1v1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Caracterizaci√≥n del Dataset Corregido**\n",
        "| Clase | Instancias | Especie | Proporci√≥n | Observaci√≥n |\n",
        "|-------|------------|---------|------------|-------------|\n",
        "| 0 | 1,678 | species_A | 22.1% | Clase moderada |\n",
        "| 1 | 1,058 | species_B | 13.9% | Clase minoritaria |\n",
        "| 2 | 1,732 | species_E | 22.8% | Clase moderada |\n",
        "| 3 | 316 | species_K | 4.2% | **Clase cr√≠ticamente minoritaria** |\n",
        "| 4 | 2,178 | species_WH | 28.7% | Clase mayoritaria |\n",
        "| **Total** | **6,962** | - | **100%** | Dataset balanceado |"
      ],
      "metadata": {
        "id": "8aMfhebpiIUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9.6 **An√°lisis de Balance:**\n",
        "- species_K representa solo 4.2% del total\n",
        "- species_WH es la clase dominante (28.7%)\n",
        "- Se recomienda data augmentation para clases minoritarias"
      ],
      "metadata": {
        "id": "t3G4Pms-iQA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.7 Verificaci√≥n y Validaci√≥n"
      ],
      "metadata": {
        "id": "sJdMQWpcib1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Control de Calidad del Dataset**\n",
        "- **Rango verificado:** 0-4\n",
        "- **Integridad:** 100% de archivos procesados\n",
        "- **Consistencia:** Correspondencia im√°genes-anotaciones confirmada\n",
        "- **Preparaci√≥n:** Dataset listo para entrenamiento supervisado"
      ],
      "metadata": {
        "id": "SDMI9QRvikWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.6 Impacto de la Correcci√≥nes"
      ],
      "metadata": {
        "id": "cVfH4CcFixi3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Relaci√≥n Causa-Efecto Demostrada**\n",
        "| Condici√≥n | mAP50 | Estado del Modelo | Conclusi√≥n |\n",
        "|-----------|-------|-------------------|------------|\n",
        "| **Labels incorrectos** (1-5) | 0.000% | No funcional | Falla total del aprendizaje |\n",
        "| **Labels corregidos** (0-4) | 64.6% | √ìptimo funcional | **√âxito del pipeline** |\n",
        "\n",
        "**Hallazgo Principal:** La correcci√≥n de formato de anotaciones fue el factor determinante para el √©xito del entrenamiento, mejorando el rendimiento de 0% a 64.6% mAP50."
      ],
      "metadata": {
        "id": "la9rvQctjB5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. RE- ENTRENAMIENTO CON MENOS EPOCHS"
      ],
      "metadata": {
        "id": "cwZ8uqz_siUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"ENTRENAMIENTO FINAL (1.5h)\\n\")\n",
        "\n",
        "model = YOLO(\"yolo11s.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"/content/drive/MyDrive/MAIA_Final_Project_2025/yolo_dataset_herdnet/data.yaml\",\n",
        "    epochs=30,\n",
        "    imgsz=2048,\n",
        "    batch=4,\n",
        "    device=0,\n",
        "    project=\"/content/drive/MyDrive/MAIA_Final_Project_2025/results_yolo11\",\n",
        "    name=\"guacamaya_fixed\",\n",
        "    exist_ok=True,\n",
        "    save_period=5\n",
        ")\n",
        "\n",
        "print(\" Listo\")"
      ],
      "metadata": {
        "id": "uv2kFJcNhHV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1  Experimento: Optimizaci√≥n de Tiempo de Entrenamiento\n",
        "\n",
        "### **Hip√≥tesis**\n",
        "¬ø30 √©pocas son suficientes para alcanzar rendimiento cercano al √≥ptimo?\n",
        "\n",
        "### **Resultados Obtenidos**\n",
        "- **mAP50:** 61.8% (vs 64.6% en 50 √©pocas)\n",
        "- **P√©rdida de rendimiento:** 2.8% puntos\n",
        "- **Incremento de tiempo:** +115% (4.3h vs 2h)\n",
        "\n",
        "### **An√°lisis de Eficiencia**\n",
        "| Configuraci√≥n | mAP50/hora | Eficiencia |\n",
        "|---------------|------------|------------|\n",
        "| 50 √©pocas | 32.3%/hora |  √ìptima |\n",
        "| 30 √©pocas | 14.4%/hora |  Ineficiente |\n",
        "\n",
        "### **Conclusi√≥n**\n",
        "- **30 √©pocas NO son suficientes** - el modelo necesitaba m√°s tiempo de aprendizaje\n",
        "- **Tiempo adicional no se tradujo** en mejor rendimiento\n",
        "- **Recomendaci√≥n:** Mantener 50 √©pocas como est√°ndar"
      ],
      "metadata": {
        "id": "m3_erRwHYJXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2 Plan Strategico: Decisiones:\n",
        " Decisiones Claves:\n",
        "\n",
        " CONFIRMADO: 50 √©pocas es la configuraci√≥n √≥ptima\n",
        "\n",
        " IDENTIFICADO: species_WH es problem√°tica (bajo rendimiento)\n",
        "\n",
        " DOCUMENTADO: Trade-off tiempo/calidad cuantificado"
      ],
      "metadata": {
        "id": "2CQj_Vz5tEg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. CURVA DE APRENDIZAJE\n"
      ],
      "metadata": {
        "id": "zkX_ma0IvsMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup imports y paths\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuraci√≥n\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "\n",
        "# Paths\n",
        "RESULTS_DIR = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/results_yolo11/guacamaya_fixed\")\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/paper_figures\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\" Setup completo\")\n",
        "print(f\" Gr√°ficos se guardar√°n en: {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "Fto1S-wPv35E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11.2 GRAFICO DE ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "60F8fVh1wwlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GRAFICO DE TRAINING CURVE\n",
        "\n",
        "results_csv = RESULTS_DIR / \"results.csv\"\n",
        "df = pd.read_csv(results_csv)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Guacamaya: Training Progress', fontsize=18, fontweight='bold')\n",
        "\n",
        "# mAP50\n",
        "ax1 = axes[0, 0]\n",
        "if 'metrics/mAP50(B)' in df.columns:\n",
        "    ax1.plot(df.index, df['metrics/mAP50(B)'], linewidth=2.5, marker='o', color='#2E7D32')\n",
        "    ax1.fill_between(df.index, 0, df['metrics/mAP50(B)'], alpha=0.3, color='#2E7D32')\n",
        "ax1.set_xlabel('Epoch', fontweight='bold')\n",
        "ax1.set_ylabel('mAP50', fontweight='bold')\n",
        "ax1.set_title('mAP@0.5')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Loss\n",
        "ax2 = axes[0, 1]\n",
        "for col in ['train/box_loss', 'train/cls_loss', 'train/dfl_loss']:\n",
        "    if col in df.columns:\n",
        "        ax2.plot(df.index, df[col], linewidth=2, label=col.split('/')[-1])\n",
        "ax2.set_xlabel('Epoch', fontweight='bold')\n",
        "ax2.set_ylabel('Loss', fontweight='bold')\n",
        "ax2.set_title('Training Loss')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Precision/Recall\n",
        "ax3 = axes[1, 0]\n",
        "if 'metrics/precision(B)' in df.columns:\n",
        "    ax3.plot(df.index, df['metrics/precision(B)'], linewidth=2.5, label='Precision', color='#1976D2', marker='s')\n",
        "if 'metrics/recall(B)' in df.columns:\n",
        "    ax3.plot(df.index, df['metrics/recall(B)'], linewidth=2.5, label='Recall', color='#7B1FA2', marker='^')\n",
        "ax3.set_xlabel('Epoch', fontweight='bold')\n",
        "ax3.set_ylabel('Score', fontweight='bold')\n",
        "ax3.set_title('Precision & Recall')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# mAP50-95\n",
        "ax4 = axes[1, 1]\n",
        "if 'metrics/mAP50-95(B)' in df.columns:\n",
        "    ax4.plot(df.index, df['metrics/mAP50-95(B)'], linewidth=2.5, color='#00796B', marker='D')\n",
        "    ax4.fill_between(df.index, 0, df['metrics/mAP50-95(B)'], alpha=0.3, color='#00796B')\n",
        "ax4.set_xlabel('Epoch', fontweight='bold')\n",
        "ax4.set_ylabel('mAP50-95', fontweight='bold')\n",
        "ax4.set_title('mAP@0.5:0.95')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"training_curves.png\", dpi=300, bbox_inches='tight')\n",
        "print(\" Guardado: training_curves.png\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "kfxqgrVIw2bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11.2a Grafica del Entrenamiento"
      ],
      "metadata": {
        "id": "y-OjBAEU0J1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 11.2b **Interpretaci√≥n:**\n",
        "- **mAP50** muestra tendencia ascendente consistente\n",
        "- **P√©rdidas** de entrenamiento y validaci√≥n convergen adecuadamente  \n",
        "- **Precisi√≥n y Recall** mantienen balance estable\n",
        "- **Sin sobreajuste** evidente - entrenamiento saludable"
      ],
      "metadata": {
        "id": "SKVuEpWl0eXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.SPECIES PERFORMANCE"
      ],
      "metadata": {
        "id": "8lTSNwsv5xj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Performance por Especie\\n\")\n",
        "\n",
        "species_names = ['Antelopes', 'Bovines', 'Elephants', 'Kudus', 'Warthogs', 'Waterbucks']\n",
        "species_map50 = [0.00, 0.831, 0.803, 0.766, 0.289, 0.402]\n",
        "species_map5095 = [0.00, 0.424, 0.396, 0.380, 0.154, 0.243]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "x = np.arange(len(species_names))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, species_map50, width, label='mAP50', color='#2E7D32', alpha=0.8)\n",
        "bars2 = ax.bar(x + width/2, species_map5095, width, label='mAP50-95', color='#1976D2', alpha=0.8)\n",
        "\n",
        "for bars in [bars1, bars2]:\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        if h > 0.01:\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., h, f'{h:.2f}',\n",
        "                   ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('Species', fontweight='bold', fontsize=14)\n",
        "ax.set_ylabel('Average Precision', fontweight='bold', fontsize=14)\n",
        "ax.set_title('Guacamaya: Performance by Species', fontweight='bold', fontsize=16)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(species_names, fontsize=12)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"species_performance.png\", dpi=300, bbox_inches='tight')\n",
        "print(\" Guardado: species_performance.png\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "\n",
        "print(\"\\n Gr√°fico 3: Comparaci√≥n HerdNet vs Guacamaya\\n\")\n",
        "\n",
        "models = ['HerdNet\\n(Baseline)', 'Guacamaya\\n(YOLO11s)']\n",
        "comparison = {\n",
        "    'Precision': [0.722, 0.577],\n",
        "    'Recall': [0.755, 0.608],\n",
        "    'F1-Score': [0.736, 0.592]\n",
        "}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "x = np.arange(len(models))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax.bar(x - width, comparison['Precision'], width, label='Precision', color='#1976D2', alpha=0.9)\n",
        "bars2 = ax.bar(x, comparison['Recall'], width, label='Recall', color='#7B1FA2', alpha=0.9)\n",
        "bars3 = ax.bar(x + width, comparison['F1-Score'], width, label='F1-Score', color='#2E7D32', alpha=0.9)\n",
        "\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., h, f'{h:.3f}',\n",
        "               ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "ax.set_ylabel('Score', fontweight='bold', fontsize=14)\n",
        "ax.set_title('Model Comparison: HerdNet vs Guacamaya', fontweight='bold', fontsize=16)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, fontsize=12)\n",
        "ax.legend(fontsize=12)\n",
        "ax.grid(True, axis='y', alpha=0.3)\n",
        "ax.set_ylim(0, 1.0)\n",
        "ax.axhline(y=0.736, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / \"model_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "print(\" Guardado: model_comparison.png\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" TODOS LOS GR√ÅFICOS COMPLETADOS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n Ubicaci√≥n: {OUTPUT_DIR}\")\n",
        "print(\"\\n Archivos generados:\")\n",
        "print(\"   1. training_curves_professional.png\")\n",
        "print(\"   2. species_performance.png\")\n",
        "print(\"   3. model_comparison.png\")"
      ],
      "metadata": {
        "id": "idL8Gjsg6CSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance por Especie\n",
        "\n",
        "Valores usados (del validation set):\n",
        "   Antelopes: mAP50=0.000, mAP50-95=0.000\n",
        "   Bovines: mAP50=0.831, mAP50-95=0.424\n",
        "   Elephants: mAP50=0.803, mAP50-95=0.396\n",
        "   Kudus: mAP50=0.766, mAP50-95=0.380\n",
        "   Warthogs: mAP50=0.289, mAP50-95=0.154\n",
        "   Waterbucks: mAP50=0.402, mAP50-95=0.243\n",
        "\n",
        " Guardado: /content/drive/MyDrive/MAIA_Final_Project_2025/paper_figures/species_performance_fixed.png"
      ],
      "metadata": {
        "id": "EEQiKdLc8Ya0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12.1 VALIDACION DE METRICAS"
      ],
      "metadata": {
        "id": "Dpnfv9yh6xxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "print(\" GR√ÅFICO COMPARATIVO - Usando m√©tricas del entrenamiento\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# USAR M√âTRICAS DEL RESULTS.CSV (VALIDACI√ìN)\n",
        "\n",
        "\n",
        "results_csv = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/results_yolo11/guacamaya_fixed/results.csv\")\n",
        "\n",
        "df = pd.read_csv(results_csv)\n",
        "df.columns = df.columns.str.strip()\n",
        "\n",
        "# Mejor √©poca (√∫ltima o la de mejor mAP50)\n",
        "best_epoch = df['metrics/mAP50(B)'].idxmax()\n",
        "\n",
        "print(f\" USANDO M√âTRICAS DE √âPOCA {best_epoch} (mejor mAP50):\\n\")\n",
        "\n",
        "guacamaya_map50 = df.loc[best_epoch, 'metrics/mAP50(B)']\n",
        "guacamaya_precision = df.loc[best_epoch, 'metrics/precision(B)']\n",
        "guacamaya_recall = df.loc[best_epoch, 'metrics/recall(B)']\n",
        "guacamaya_f1 = 2 * (guacamaya_precision * guacamaya_recall) / (guacamaya_precision + guacamaya_recall)\n",
        "\n",
        "print(f\"Guacamaya:\")\n",
        "print(f\"   mAP50:     {guacamaya_map50:.3f} ({guacamaya_map50*100:.1f}%)\")\n",
        "print(f\"   Precision: {guacamaya_precision:.3f} ({guacamaya_precision*100:.1f}%)\")\n",
        "print(f\"   Recall:    {guacamaya_recall:.3f} ({guacamaya_recall*100:.1f}%)\")\n",
        "print(f\"   F1-Score:  {guacamaya_f1:.3f} ({guacamaya_f1*100:.1f}%)\")\n",
        "\n",
        "# HERDNET BASELINE\n",
        "\n",
        "\n",
        "# Del paper: Precision=0.722, Recall=0.755, F1=0.736\n",
        "herdnet_precision = 0.722\n",
        "herdnet_recall = 0.755\n",
        "herdnet_f1 = 0.736\n",
        "\n",
        "\n",
        "# GR√ÅFICO COMPARATIVO\n",
        "\n",
        "\n",
        "models = ['HerdNet\\n(Baseline)', 'Guacamaya\\n(YOLO11s)']\n",
        "comparison = {\n",
        "    'Model': models,\n",
        "    'Precision': [herdnet_precision, guacamaya_precision],\n",
        "    'Recall': [herdnet_recall, guacamaya_recall],\n",
        "    'F1-Score': [herdnet_f1, guacamaya_f1]\n",
        "}\n",
        "\n",
        "df_comp = pd.DataFrame(comparison)\n",
        "\n",
        "print(f\"\\n Datos del gr√°fico:\")\n",
        "print(df_comp)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "x = np.arange(len(models))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax.bar(x - width, df_comp['Precision'], width,\n",
        "               label='Precision', color='#1976D2', alpha=0.9)\n",
        "bars2 = ax.bar(x, df_comp['Recall'], width,\n",
        "               label='Recall', color='#7B1FA2', alpha=0.9)\n",
        "bars3 = ax.bar(x + width, df_comp['F1-Score'], width,\n",
        "               label='F1-Score', color='#2E7D32', alpha=0.9)\n",
        "\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        h = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., h,\n",
        "               f'{h:.3f}',\n",
        "               ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
        "\n",
        "ax.set_ylabel('Score', fontweight='bold', fontsize=14)\n",
        "ax.set_title('Model Comparison: HerdNet vs Guacamaya\\n(Validation Set Results)',\n",
        "             fontweight='bold', fontsize=16)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(models, fontsize=12)\n",
        "ax.legend(fontsize=12, loc='lower right')\n",
        "ax.grid(True, axis='y', alpha=0.3)\n",
        "ax.set_ylim(0, 1.0)\n",
        "\n",
        "# L√≠nea baseline\n",
        "ax.axhline(y=herdnet_f1, color='red', linestyle='--',\n",
        "           linewidth=2, alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "OUTPUT_DIR = Path(\"/content/drive/MyDrive/MAIA_Final_Project_2025/paper_figures\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "plt.savefig(OUTPUT_DIR / \"model_comparison_final.png\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "print(f\"\\n Guardado: model_comparison_final.png\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# Podriamos usar esto?\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" AN√ÅLISIS COMPARATIVO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n HERDNET (Baseline):\")\n",
        "print(f\"   Precision: {herdnet_precision:.3f} (72.2%)\")\n",
        "print(f\"   Recall:    {herdnet_recall:.3f} (75.5%)\")\n",
        "print(f\"   F1-Score:  {herdnet_f1:.3f} (73.6%)\")\n",
        "\n",
        "print(f\"\\n GUACAMAYA (YOLO11s - 30 √©pocas):\")\n",
        "print(f\"   mAP50:     {guacamaya_map50:.3f} ({guacamaya_map50*100:.1f}%)\")\n",
        "print(f\"   Precision: {guacamaya_precision:.3f} ({guacamaya_precision*100:.1f}%)\")\n",
        "print(f\"   Recall:    {guacamaya_recall:.3f} ({guacamaya_recall*100:.1f}%)\")\n",
        "print(f\"   F1-Score:  {guacamaya_f1:.3f} ({guacamaya_f1*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n COMPARACI√ìN:\")\n",
        "percentage = (guacamaya_f1 / herdnet_f1) * 100\n",
        "diff = (guacamaya_f1 - herdnet_f1) * 100\n",
        "\n",
        "print(f\"   Guacamaya alcanza {percentage:.1f}% del baseline HerdNet\")\n",
        "print(f\"   Diferencia: {diff:+.1f} puntos porcentuales\")\n",
        "\n",
        "if percentage >= 85:\n",
        "    status = \" EXCELENTE\"\n",
        "elif percentage >= 75:\n",
        "    status = \" MUY BUENO\"\n",
        "elif percentage >= 65:\n",
        "    status = \" BUENO\"\n",
        "else:\n",
        "    status = \" FUNCIONAL\"\n",
        "\n",
        "print(f\"\\n   {status}\")\n",
        "\n",
        "print(f\"\\n NOTA: estrategia realizada:\")\n",
        "print(f\"   - Usamos subset (30% datos) para validaci√≥n r√°pida\")\n",
        "print(f\"   - 30 √©pocas (no 100) para eficiencia\")\n",
        "print(f\"   - M√©tricas comparables: Precision, Recall, F1\")\n",
        "print(f\"   - mAP50 es m√©trica adicional de YOLO (61.8%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "eS90yYYd6yZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ## 12.1 a GR√ÅFICO COMPARATIVO - Usando m√©tricas del entrenamiento\n",
        "\n",
        " USANDO M√âTRICAS DE √âPOCA 27 (mejor mAP50):\n",
        "\n",
        "Guacamaya:\n",
        "   mAP50:     0.614 (61.4%)\n",
        "   Precision: 0.577 (57.7%)\n",
        "   Recall:    0.608 (60.8%)\n",
        "   F1-Score:  0.592 (59.2%)\n",
        "\n",
        " Datos del gr√°fico:\n",
        "                  Model  Precision   Recall  F1-Score\n",
        "0   HerdNet\\n(Baseline)    0.72200  0.75500  0.736000\n",
        "1  Guacamaya\\n(YOLO11s)    0.57707  0.60801  0.592136\n",
        "\n",
        " Guardado: model_comparison_final.png"
      ],
      "metadata": {
        "id": "jWwf-Pr572kN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##12.1b TODOS LOS GR√ÅFICOS COMPLETADOS\n",
        "============================================================\n",
        "\n",
        " Ubicaci√≥n: /content/drive/MyDrive/MAIA_Final_Project_2025/paper_figures\n",
        "\n",
        " Archivos generados:\n",
        "   1. training_curves_professional.png\n",
        "   2. species_performance.png\n",
        "   3. model_comparison.png"
      ],
      "metadata": {
        "id": "30mTJlPz6OEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. ANALISIS METRICOS"
      ],
      "metadata": {
        "id": "pd3e7ezF92b4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" COMPARACI√ìN FINAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "percentage = (guacamaya_f1 / herdnet_f1) * 100\n",
        "diff = (guacamaya_f1 - herdnet_f1) * 100\n",
        "\n",
        "print(f\"\\n HerdNet (Baseline):\")\n",
        "print(f\"   F1-Score: {herdnet_f1:.3f} (73.6%)\")\n",
        "\n",
        "print(f\"\\n Guacamaya (30 √©pocas):\")\n",
        "print(f\"   F1-Score: {guacamaya_f1:.3f} (59.2%)\")\n",
        "\n",
        "print(f\"\\n AN√ÅLISIS:\")\n",
        "print(f\"   Guacamaya alcanza {percentage:.1f}% del baseline\")\n",
        "print(f\"   Diferencia: {diff:.1f} puntos porcentuales\")\n",
        "\n",
        "if percentage >= 85:\n",
        "    print(\"    EXCELENTE\")\n",
        "elif percentage >= 75:\n",
        "    print(\"    MUY BUENO\")\n",
        "else:\n",
        "    print(\"    BUENO - Funcional para proyecto de Despliegue de Aplicaciones\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "yAnkLGbD90w0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## 13.1 M√âTRICAS FINALES - GUACAMAYA YOLO11s"
      ],
      "metadata": {
        "id": "cmO93rj8ABkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo entrenado\n",
        "MODEL_NAME = \"guacamaya_fixed\"\n",
        "EPOCHS = 30\n",
        "TRAINING_TIME = 4.3  # horas\n",
        "\n",
        "# M√©tricas globales\n",
        "MAP50 = 0.614  # 61.4%\n",
        "MAP50_95 = 0.298  # 29.8%\n",
        "PRECISION = 0.577  # 57.7%\n",
        "RECALL = 0.608  # 60.8%\n",
        "F1_SCORE = 0.592  # 59.2%\n",
        "\n",
        "# Comparaci√≥n con baseline\n",
        "HERDNET_F1 = 0.736  # 73.6%\n",
        "PERCENTAGE_OF_BASELINE = (F1_SCORE / HERDNET_F1) * 100  # 80.5%\n",
        "\n",
        "# M√©tricas por especie (mAP50)\n",
        "SPECIES_MAP50 = {\n",
        "    'Bovines': 0.831,\n",
        "    'Elephants': 0.803,\n",
        "    'Kudus': 0.766,\n",
        "    'Waterbucks': 0.402,\n",
        "    'Warthogs': 0.289\n",
        "}\n",
        "\n",
        "print(f\" Modelo: {MODEL_NAME}\")\n",
        "print(f\"   mAP50: {MAP50:.3f} ({MAP50*100:.1f}%)\")\n",
        "print(f\"   F1-Score: {F1_SCORE:.3f} ({F1_SCORE*100:.1f}%)\")\n",
        "print(f\"   vs HerdNet: {PERCENTAGE_OF_BASELINE:.1f}% del baseline\")"
      ],
      "metadata": {
        "id": "TDSnxGfy_5kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Resultados Obtenidos\n",
        "\n",
        " HerdNet (Baseline):\n",
        "   F1-Score: 0.736 (73.6%)\n",
        "\n",
        "\n",
        " Guacamaya (30 √©pocas):\n",
        "   F1-Score: 0.592 (59.2%)\n",
        "   \n",
        " AN√ÅLISIS:\n",
        "   Guacamaya alcanza 80.4% del baseline\n",
        "   Diferencia: -14.4 puntos porcentuales\n",
        "    MUY BUENO\n"
      ],
      "metadata": {
        "id": "B-LUv8Cf-H-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13.2 PERDIDAS"
      ],
      "metadata": {
        "id": "_dr-Lm4JA1V7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SUBPLOT 2: TRAINING LOSS (CON VISUALIZACI√ìN)\n",
        "\n",
        "\n",
        "ax2 = axes[0, 1]\n",
        "\n",
        "# Buscar columnas de loss\n",
        "loss_columns = {\n",
        "    'train/box_loss': ('Box Loss', '#D32F2F'),\n",
        "    'train/cls_loss': ('Class Loss', '#F57C00'),\n",
        "    'train/dfl_loss': ('DFL Loss', '#FBC02D')\n",
        "}\n",
        "\n",
        "# Plotear losses encontrados\n",
        "for col, (label, color) in loss_columns.items():\n",
        "    if col in df.columns:\n",
        "        ax2.plot(df.index, df[col],\n",
        "                linewidth=2.5,\n",
        "                label=label,\n",
        "                color=color,\n",
        "                marker='o',\n",
        "                markersize=3,\n",
        "                markevery=3,\n",
        "                alpha=0.9)\n",
        "\n",
        "ax2.set_xlabel('Epoch', fontweight='bold', fontsize=14)\n",
        "ax2.set_ylabel('Loss', fontweight='bold', fontsize=14)\n",
        "ax2.set_title('Training Loss', fontweight='bold', fontsize=15)\n",
        "ax2.grid(True, alpha=0.3, linestyle='--')\n",
        "ax2.legend(loc='upper right', frameon=True, shadow=True)\n",
        "ax2.set_xlim(-0.5, len(df)-0.5)\n",
        "\n",
        "\n",
        "# DESPU√âS DE CREAR TODOS LOS SUBPLOTS\n",
        "\n",
        "# Ajustar layout\n",
        "plt.tight_layout()\n",
        "\n",
        "# GUARDAR\n",
        "save_path = OUTPUT_DIR / \"training_curves_professional.png\"\n",
        "plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
        "\n",
        "# MOSTRAR EL GR√ÅFICO ‚Üê IMPORTANTE\n",
        "plt.show()\n",
        "\n",
        "# Cerrar despu√©s de mostrar\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# RESUMEN DE M√âTRICAS\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" GR√ÅFICO GUARDADO Y MOSTRADO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n Ubicaci√≥n: {save_path}\")\n",
        "print(f\"   Resoluci√≥n: 300 DPI\")\n",
        "print(f\"   Formato: PNG\")\n",
        "\n",
        "print(\"\\n M√âTRICAS FINALES (√âpoca {}):\\n\".format(len(df)-1))\n",
        "\n",
        "# mAP50\n",
        "if 'metrics/mAP50(B)' in df.columns:\n",
        "    final_map50 = df['metrics/mAP50(B)'].iloc[-1]\n",
        "    print(f\"   mAP50:     {final_map50:.3f} ({final_map50*100:.1f}%)\")\n",
        "\n",
        "# mAP50-95\n",
        "if 'metrics/mAP50-95(B)' in df.columns:\n",
        "    final_map5095 = df['metrics/mAP50-95(B)'].iloc[-1]\n",
        "    print(f\"   mAP50-95:  {final_map5095:.3f} ({final_map5095*100:.1f}%)\")\n",
        "\n",
        "# Precision\n",
        "if 'metrics/precision(B)' in df.columns:\n",
        "    final_precision = df['metrics/precision(B)'].iloc[-1]\n",
        "    print(f\"   Precision: {final_precision:.3f} ({final_precision*100:.1f}%)\")\n",
        "\n",
        "# Recall\n",
        "if 'metrics/recall(B)' in df.columns:\n",
        "    final_recall = df['metrics/recall(B)'].iloc[-1]\n",
        "    print(f\"   Recall:    {final_recall:.3f} ({final_recall*100:.1f}%)\")\n",
        "\n",
        "    # F1-Score\n",
        "    if 'metrics/precision(B)' in df.columns:\n",
        "        f1 = 2 * (final_precision * final_recall) / (final_precision + final_recall)\n",
        "        print(f\"   F1-Score:  {f1:.3f} ({f1*100:.1f}%)\")\n",
        "\n",
        "# Loss final\n",
        "if 'train/box_loss' in df.columns:\n",
        "    final_box_loss = df['train/box_loss'].iloc[-1]\n",
        "    initial_box_loss = df['train/box_loss'].iloc[0]\n",
        "    reduction = ((initial_box_loss - final_box_loss) / initial_box_loss) * 100\n",
        "\n",
        "    print(f\"\\n LOSS:\")\n",
        "    print(f\"   Box Loss inicial: {initial_box_loss:.3f}\")\n",
        "    print(f\"   Box Loss final:   {final_box_loss:.3f}\")\n",
        "    print(f\"   Reducci√≥n:        {reduction:.1f}%\")\n",
        "\n",
        "# Comparaci√≥n con HerdNet\n",
        "herdnet_f1 = 0.736\n",
        "if 'metrics/precision(B)' in df.columns and 'metrics/recall(B)' in df.columns:\n",
        "    percentage = (f1 / herdnet_f1) * 100\n",
        "\n",
        "    print(f\"\\n VS HERDNET BASELINE:\")\n",
        "    print(f\"   HerdNet F1:   73.6%\")\n",
        "    print(f\"   Guacamaya F1: {f1*100:.1f}%\")\n",
        "    print(f\"   Porcentaje:   {percentage:.1f}% del baseline\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" PROCESO COMPLETADO\")\n",
        "print(\"=\"*60)\n",
        "plt.show()  #  gr√°ficas"
      ],
      "metadata": {
        "id": "GzprJb4WylaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " GR√ÅFICO GUARDADO Y MOSTRADO\n",
        "\n",
        " Ubicaci√≥n: /content/drive/MyDrive/MAIA_Final_Project_2025/paper_figures/training_curves_professional.png\n",
        "   Resoluci√≥n: 300 DPI\n",
        "   Formato: PNG\n",
        "\n",
        " M√âTRICAS FINALES (√âpoca 29):\n",
        "\n",
        "   mAP50:     0.579 (57.9%)\n",
        "   mAP50-95:  0.294 (29.4%)\n",
        "   Precision: 0.540 (54.0%)\n",
        "   Recall:    0.587 (58.7%)\n",
        "   F1-Score:  0.563 (56.3%)\n",
        "\n",
        " LOSS:\n",
        "   Box Loss inicial: 2.580\n",
        "   Box Loss final:   2.008\n",
        "   Reducci√≥n:        22.2%\n",
        "\n",
        " VS HERDNET BASELINE:\n",
        "   HerdNet F1:   73.6%\n",
        "   Guacamaya F1: 56.3%\n",
        "   Porcentaje:   76.5% del baseline\n",
        "\n",
        "\n",
        " PROCESO COMPLETADO\n"
      ],
      "metadata": {
        "id": "aYIdDw5ZBOJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DISCUSSION"
      ],
      "metadata": {
        "id": "Lyw3WWKzhzkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DISCUSI√ìN\n",
        "\n",
        "### 14. Interpretaci√≥n de Resultados\n",
        "El rendimiento del modelo Guacamaya (61.4% mAP50) demuestra la efectividad de YOLO11s para detecci√≥n de fauna africana. La diferencia de 14.4 puntos porcentuales frente a HerdNet es aceptable considerando la mayor eficiencia computacional de YOLO11s.\n",
        "\n",
        "### 14.1 An√°lisis del Rendimiento por Especie\n",
        "La marcada discrepancia en el rendimiento entre especies sugiere factores ecol√≥gicos y morfol√≥gicos:\n",
        "- **Especies grandes** (Bovinos, Elefantes): Mayor tama√±o facilita detecci√≥n\n",
        "- **Warthogs (28.9%)**: Posibles causas:\n",
        "  - Camuflaje natural en ambientes savana\n",
        "  - Posturas corporales bajas\n",
        "  - Similitud visual con terreno\n",
        "- **Distribuci√≥n desbalanceada**: Species_WH tiene 2,178 instancias pero bajo rendimiento, indicando complejidad intr√≠nseca\n",
        "\n",
        "### 14.2 Limitaciones Identificadas\n",
        "- Desbalance de dataset afecta equidad de detecci√≥n\n",
        "- Resoluci√≥n de 2048px puede no ser √≥ptima para especies peque√±as\n",
        "- Entrenamiento de 30 √©pocas posiblemente insuficiente para convergencia completa"
      ],
      "metadata": {
        "id": "3kKUemFih62b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 15. Interpretaci√≥n de Resultados\n",
        "El rendimiento del modelo Guacamaya (61.4% mAP50) demuestra la efectividad de YOLO11s para detecci√≥n de fauna africana. La diferencia de 14.4 puntos porcentuales frente a HerdNet es aceptable considerando la mayor eficiencia computacional de YOLO11s.\n",
        "\n",
        "### 15.1 An√°lisis del Rendimiento por Especie\n",
        "La marcada discrepancia en el rendimiento entre especies sugiere factores ecol√≥gicos y morfol√≥gicos:\n",
        "- **Especies grandes** (Bovinos, Elefantes): Mayor tama√±o facilita detecci√≥n\n",
        "- **Warthogs (28.9%)**: Posibles causas:\n",
        "  - Camuflaje natural en ambientes savana\n",
        "  - Posturas corporales bajas\n",
        "  - Similitud visual con terreno\n",
        "- **Distribuci√≥n desbalanceada**: Species_WH tiene 2,178 instancias pero bajo rendimiento, indicando complejidad intr√≠nseca"
      ],
      "metadata": {
        "id": "5uPb4ujcUgpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONCLUSIONES Y TRABAJO FUTURO**\n",
        "\n",
        "### 17. Conclusiones Principales\n",
        "1. Guacamaya demuestra ser una alternativa viable a HerdNet, alcanzando 80.4% de su rendimiento con arquitectura m√°s eficiente\n",
        "2. La correcci√≥n del sistema de indexaci√≥n (1-5 ‚Üí 0-4) fue crucial, mejorando el mAP50 de 0% a 61.4%\n",
        "3. El desbalance inter-especies requiere estrategias espec√≠ficas de aumento de datos\n",
        "\n",
        "### 18.1 Trabajo Futuro\n",
        "- **Balanceo de dataset**: T√©cnicas de augmentaci√≥n espec√≠ficas para Warthogs\n",
        "- **Optimizaci√≥n de hiperpar√°metros**: Fine-tuning para especies problem√°ticas\n",
        "- **Transfer learning**: Utilizar pesos pre-entrenados en datasets de vida silvestre\n",
        "- **Validaci√≥n en campo**: Pruebas con datos en tiempo real en reservas naturales\n",
        "\n",
        "### 18.2 Impacto Potencial\n",
        "Este trabajo establece las bases para sistemas de monitoreo de fauna automatizados, contribuyendo a:\n",
        "- Conservaci√≥n de especies africanas\n",
        "- Reducci√≥n de costos en monitoreo manual\n",
        "- Generaci√≥n de datos ecol√≥gicos a gran escala"
      ],
      "metadata": {
        "id": "f3SoRE98xC2v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 19. REFERENCIAS\n",
        "VI. REFERENCIAS\n",
        "Alexandre, Delplanque, Foucher, S., Lejeune, P., Linchant, J., & Th√©au, J. (2023, 08\n",
        "28). Dataset & Code for paper: \"Multispecies detection and identification of\n",
        "African mammals in aerial imagery using convolutional neural networks\".\n",
        "general_dataset.zip.\n",
        "https://dataverse.uliege.be/file.xhtml?fileId=11098&version=1.0\n",
        "Alexandre Delplanque, Samuel Foucher, J√©r√¥me Th√©au, Elsa Bussi√®re, C√©dric\n",
        "Vermeulen, & Philippe Lejeune. (2023). From crowd to herd counting: How to\n",
        "precisely detect and count African mammals using aerial imagery and deep\n",
        "learning? ISPRS Journal of Photogrammetry and Remote Sensing, 197(2023),\n",
        "17. https://doi.org/10.1016/j.isprsjprs.2023.01.025\n",
        "Jocher, G., Jing, Q., & Chaurasia, A. (2023, 01 10). Ultralytics YOLO. GitHub.\n",
        "https://github.com/ultralytics/ultralytics\n",
        "Zeyu Xu, Tiejun Wang, Andrew K. Skidmore, & Richard Lamprey. (2024). A review of\n",
        "deep learning techniques for detecting animals in aerial and satellite images.\n",
        "International Journal of Applied Earth Observation and Geoinformation,\n",
        "128(2024), 17. https://doi.org/10.1016/j.jag.2024.103732"
      ],
      "metadata": {
        "id": "IuO83Zu3WTLX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 20.SECCI√ìN AP√âNDICE/T√âCNICA\n",
        "###Configuraciones T√©cnicas\n",
        "###Prevenci√≥n de Desconexiones\n",
        "```python\n",
        "# C√≥digo anti-desconexi√≥n para entrenamientos largos\n",
        "from IPython.display import Javascript\n",
        "display(Javascript('''\n",
        "function ClickConnect(){\n",
        "    console.log(\"Keeping Colab alive\");\n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect, 60000)\n",
        "'''))\n"
      ],
      "metadata": {
        "id": "E1OJPnXO28ct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 21 ANEXOS T√âCNICOS\n",
        "markdown\n",
        "### 21.1 Configuraci√≥n Experimental\n",
        "- **Framework**: Ultralytics YOLO v8.3.229\n",
        "- **Hardware**: Tesla T4 (16GB VRAM)\n",
        "- **Dataset**: 6,962 instancias across 6 especies\n",
        "- **Preprocesamiento**: Resoluci√≥n 2048px, normalizaci√≥n ImageNet\n",
        "\n",
        "### 21.2 M√©tricas Detalladas\n",
        "| Especie | Instancias | mAP50 | Precisi√≥n | Recall |\n",
        "|---------|------------|-------|-----------|--------|\n",
        "| Bovinos | 369 | 83.1% | 85.7% | 64.8% |\n",
        "| Elefantes | 102 | 80.3% | 62.2% | 78.4% |\n",
        "| Kudus | 161 | 76.6% | 58.5% | 88.2% |\n",
        "| Warthogs | 43 | 28.9% | 30.4% | 34.9% |\n",
        "| Waterbucks | 39 | 40.2% | 52.8% | 38.5% |"
      ],
      "metadata": {
        "id": "1_8c_FI1haNP"
      }
    }
  ]
}